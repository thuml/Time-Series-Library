# Phase 2 训练状态实时报告

**启动时间**: 2026-01-22 13:21
**当前状态**: 🟢 全部运行中
**预计完成**: 2026-01-22 19:21 (约6小时)

---

## 📊 当前进度总览

### 1. 基线训练 (iTransformerDiffusionDirect)
- **状态**: ⏳ 训练中 (Epoch 2/30)
- **进度**: 6.7%
- **训练损失**: 0.7648 → 0.6073 ✓ 下降中
- **验证损失**: 604.08 → 646.24
- **课程学习**: α=1.00 → 0.92 ✓ 权重调度正常
- **日志**: `logs/phase2/baseline.log`

### 2. iTransformer 对比训练
- **状态**: ⏳ 训练中 (Epoch 13/30)
- **进度**: 43.3%
- **训练损失**: 0.3674 → 0.3661 ✓ 收敛良好
- **验证损失**: 0.6923 → 0.6958
- **日志**: `logs/phase2/iTransformer.log`

### 3. PatchTST 对比训练
- **状态**: ⏳ 训练中 (Epoch 5/30)
- **进度**: 16.7%
- **训练损失**: 0.3773 → 0.3668 ✓ 下降中
- **验证损失**: 0.6920 → 0.6881 ✓ 最佳验证损失
- **日志**: `logs/phase2/PatchTST.log`

### 4. TimesNet 对比训练
- **状态**: ⏳ 训练中 (Epoch 1/30)
- **进度**: 3.3%
- **训练损失**: 0.4960
- **验证损失**: 0.8365
- **日志**: `logs/phase2/TimesNet.log`

---

## 🖥️ 系统资源

- **GPU**: NVIDIA GeForce RTX 4060 Laptop GPU
- **GPU 使用率**: 99% ✓ 高效运行
- **显存使用**: 2356 MiB / 8188 MiB (28.8%)
- **运行进程**: 44 个 Python 进程

---

## 📈 初步观察

### 训练速度对比
1. **iTransformer**: 最快 (~5.5s/epoch)
2. **PatchTST**: 较快 (~11s/epoch)
3. **基线**: 中等 (~30s/epoch) - 包含扩散训练
4. **TimesNet**: 最慢 (~42s/epoch)

### 性能趋势
- **PatchTST** 目前验证损失最低 (0.6881)
- **iTransformer** 训练稳定，收敛快
- **基线** 训练损失下降良好，课程学习权重调度正常工作
- **TimesNet** 刚开始，需要观察

### 基线训练特殊指标
- **MSE 损失**: 0.4752 → 0.3963 ✓
- **扩散损失**: 1.0545 → 0.8185 ✓
- **α 权重**: 1.00 → 0.92 (课程学习，warmup 中)

---

## 🔧 监控命令

### 实时监控
```bash
# 持续监控（每30秒刷新）
watch -n 30 bash scripts/phase2_monitor.sh

# 一次性查看状态
bash scripts/phase2_monitor.sh
```

### 查看日志
```bash
# 查看基线训练实时日志
tail -f logs/phase2/baseline.log

# 查看所有模型日志
tail -f logs/phase2/*.log

# 查看特定模型
tail -f logs/phase2/iTransformer.log
```

### 查看进程
```bash
# 查看所有训练进程
ps aux | grep "python.*run.py"

# 查看 GPU 使用
nvidia-smi

# 持续监控 GPU
watch -n 5 nvidia-smi
```

---

## ⚠️ 注意事项

### 正常现象
- ✅ 基线训练比对比模型慢（包含扩散训练）
- ✅ 验证损失偶尔上升（正常波动）
- ✅ GPU 使用率接近 100%

### 需要关注
- ⚠️ 如果验证损失持续上升 → 可能过拟合
- ⚠️ 如果出现 NaN/Inf → 训练不稳定
- ⚠️ 如果 GPU 使用率突然降低 → 可能训练卡住

### 停止训练（如需）
```bash
# 停止所有训练
kill 48320 48483 48645 48728

# 或者找到所有训练进程并停止
pkill -f "python.*run.py"
```

---

## 📅 预计时间线

| 时间 | 事件 |
|------|------|
| 13:21 | ✅ 训练启动 |
| ~14:30 | iTransformer 可能完成 (1小时) |
| ~15:00 | PatchTST 可能完成 (1.5小时) |
| ~16:30 | TimesNet 可能完成 (3小时) |
| ~19:00 | 基线训练可能完成 (6小时) |

*注: 实际时间可能因 early stopping 而缩短*

---

## 📊 训练完成后的检查清单

### 1. 收集结果
```bash
# 查看所有 checkpoint 目录
ls -lh checkpoints/ | grep "_baseline_"

# 查看结果文件
find checkpoints/ -name "result.txt" -exec cat {} \;
```

### 2. 提取指标
从各模型的 `result.txt` 提取：
- MSE, MAE, RMSE (点预测)
- CRPS (仅基线模型)
- 校准度: 50%, 90% (仅基线模型)

### 3. 对比分析
创建性能对比表格，识别：
- 基线 vs iTransformer: 扩散模型的增益
- 基线 vs PatchTST/TimesNet: 架构差异
- 频域损失是否偏高 → 决定是否需要 FR2

### 4. 决策优化方向
- 频域损失高 → FR2
- 校准度差 → 温度缩放
- 整体性能差 → 增大容量/延长训练

---

**最后更新**: 2026-01-22 13:23
**更新频率**: 运行 `bash scripts/phase2_monitor.sh` 查看最新状态

---

## 🎯 下一步行动

**等待训练完成** (预计 4-6 小时):
1. ⏳ 让训练继续运行
2. 📊 定期查看监控脚本
3. 🔍 训练完成后收集并分析结果
4. 📝 创建 Phase 2 分析报告
5. 🚀 根据分析结果决定 Phase 2.3 的优化方向

**监控建议**:
- 每 30 分钟查看一次进度
- 关注验证损失是否持续下降
- 注意是否有异常错误信息

**联系方式**: 如有问题查看日志文件或监控脚本输出
