# iTransformerDiffusionDirect æŠ€æœ¯æ–‡æ¡£

## ğŸ“– ç›®å½•

1. [æ¨¡å‹æ€æƒ³](#æ¨¡å‹æ€æƒ³)
2. [æ¨¡å‹æ¶æ„](#æ¨¡å‹æ¶æ„)
3. [æ•°å­¦åŸç†](#æ•°å­¦åŸç†)
4. [è®­ç»ƒç­–ç•¥](#è®­ç»ƒç­–ç•¥)
5. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
6. [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
7. [å®éªŒé…ç½®](#å®éªŒé…ç½®)
8. [æ‰©å±•æ–¹å‘](#æ‰©å±•æ–¹å‘)

---

## ğŸ¯ æ¨¡å‹æ€æƒ³

### æ ¸å¿ƒåŠ¨æœº

iTransformerDiffusionDirect çš„è®¾è®¡æºäºå¯¹æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜çš„æ€è€ƒï¼š

1. **å¤šå˜é‡ä¾èµ–å»ºæ¨¡**: ä¼ ç»ŸTransformeråœ¨æ—¶é—´ç»´åº¦ä¸Šåšæ³¨æ„åŠ›ï¼Œä½†æ—¶åºæ•°æ®ä¸­å˜é‡é—´çš„ä¾èµ–å…³ç³»åŒæ ·é‡è¦
2. **ä¸ç¡®å®šæ€§é‡åŒ–**: ç¡®å®šæ€§é¢„æµ‹æ— æ³•æä¾›é¢„æµ‹ç½®ä¿¡åº¦ï¼Œè€Œæ¦‚ç‡é¢„æµ‹å¯¹å†³ç­–è‡³å…³é‡è¦

### è®¾è®¡å“²å­¦

**ç›´æ¥é¢„æµ‹ + æ¡ä»¶æ‰©æ•£**:
- **ç›´æ¥é¢„æµ‹**: ä¸é¢„æµ‹æ®‹å·®ï¼Œç›´æ¥é¢„æµ‹ç›®æ ‡å€¼ï¼Œè®­ç»ƒæ›´ç¨³å®š
- **æ¡ä»¶æ‰©æ•£**: åˆ©ç”¨iTransformeræå–çš„ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼ŒæŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹
- **å¤šå‚æ•°åŒ–**: æ”¯æŒxâ‚€/Îµ/vä¸‰ç§å‚æ•°åŒ–ï¼Œé€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚

### ä¸ç›¸å…³å·¥ä½œçš„åŒºåˆ«

| æ¨¡å‹ | æ³¨æ„åŠ›ç»´åº¦ | é¢„æµ‹ç±»å‹ | è®­ç»ƒç­–ç•¥ | ç‰¹ç‚¹ |
|------|------------|----------|----------|------|
| **Transformer** | æ—¶é—´ç»´åº¦ | ç¡®å®šæ€§ | ç«¯åˆ°ç«¯ | ç»å…¸æ–¹æ³• |
| **iTransformer** | å˜é‡ç»´åº¦ | ç¡®å®šæ€§ | ç«¯åˆ°ç«¯ | å˜é‡çº§æ³¨æ„åŠ› |
| **iTransformerDiffusion** | å˜é‡ç»´åº¦ | æ¦‚ç‡æ€§ | ä¸¤é˜¶æ®µ | æ®‹å·®é¢„æµ‹ |
| **iTransformerDiffusionDirect** | å˜é‡ç»´åº¦ | æ¦‚ç‡æ€§ | ç«¯åˆ°ç«¯/ä¸¤é˜¶æ®µ | ç›´æ¥é¢„æµ‹ |

---

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

### æ•´ä½“æ•°æ®æµ

```
è¾“å…¥: x_hist [B, seq_len, N]
     â”‚
     â–¼ å®ä¾‹å½’ä¸€åŒ–
x_norm = (x_hist - mean) / std
     â”‚
     â–¼ ç»´åº¦ç½®æ¢
x_permute [B, N, seq_len]
     â”‚
     â–¼ iTransformerç¼–ç å™¨
z [B, N, d_model] (æ¡ä»¶ç‰¹å¾)
     â”‚
     â”œâ”€â–¶ ç¡®å®šæ€§é¢„æµ‹åˆ†æ”¯
     â”‚    â–¼ çº¿æ€§æŠ•å½±
     â”‚  y_det [B, N, pred_len]
     â”‚    â–¼ ç»´åº¦ç½®æ¢ + åå½’ä¸€åŒ–
     â”‚  y_det [B, pred_len, N]
     â”‚
     â””â”€â–¶ æ‰©æ•£é¢„æµ‹åˆ†æ”¯
          â–¼ å™ªå£°æ·»åŠ 
          x_t = âˆšá¾±_t * xâ‚€ + âˆš(1-á¾±_t) * Îµ
          â–¼ 1D U-Netå»å™ª
          pred = UNet1D(x_t, t, z)
          â–¼ é€†å‘é‡‡æ ·
          y_samples [n_samples, B, pred_len, N]
```

### iTransformer Backbone

#### å˜é‡çº§æ³¨æ„åŠ›æœºåˆ¶

ä¼ ç»ŸTransformer:
```
æ—¶é—´æ­¥æ³¨æ„åŠ›: [seq_len, seq_len]
Query: æ—¶é—´æ­¥tçš„è¡¨ç¤º
Key:   æ—¶é—´æ­¥sçš„è¡¨ç¤º  
Value: æ—¶é—´æ­¥sçš„è¡¨ç¤º
```

iTransformer:
```
å˜é‡æ³¨æ„åŠ›: [N_vars, N_vars]
Query: å˜é‡içš„è¡¨ç¤º
Key:   å˜é‡jçš„è¡¨ç¤º
Value: å˜é‡jçš„è¡¨ç¤º
```

#### æ•°æ®åµŒå…¥ (DataEmbedding_inverted)

```python
# è¾“å…¥: [B, seq_len, N] -> [B, N, d_model]
class DataEmbedding_inverted:
    def __init__(self, seq_len, d_model, embed_type, freq, dropout):
        # 1. ä½ç½®ç¼–ç  (seq_len -> d_model)
        self.pos_encoding = PositionalEncoding(seq_len, d_model)
        
        # 2. æ—¶é—´ç‰¹å¾ç¼–ç  (å¯é€‰)
        if embed_type != 'timeF':
            self.temporal_embedding = TemporalEmbedding(freq)
        
        # 3. çº¿æ€§æŠ•å½± (seq_len -> d_model)
        self.value_embedding = nn.Linear(seq_len, d_model)
        
        # 4. Dropout
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x, x_mark=None):
        # x: [B, seq_len, N] -> [B, N, seq_len]
        x = x.permute(0, 2, 1)
        
        # å€¼åµŒå…¥: [B, N, seq_len] -> [B, N, d_model]
        x = self.value_embedding(x) + self.pos_encoding
        
        # æ—¶é—´ç‰¹å¾åµŒå…¥ (å¯é€‰)
        if x_mark is not None:
            x = x + self.temporal_embedding(x_mark)
        
        return self.dropout(x)
```

### 1D U-Net å»å™ªç½‘ç»œ

#### ç½‘ç»œç»“æ„

```
è¾“å…¥: [B, N, pred_len]
  â”‚
  â–¼ åˆå§‹å·ç§¯
h [B, C0, pred_len]
  â”‚
  â–¼ ç¼–ç å™¨ (4ä¸ªDownBlock)
  â”œâ”€â”€ ResBlock1D + FiLM + ä¸‹é‡‡æ ·
  â”œâ”€â”€ è·³è·ƒè¿æ¥ä¿å­˜
  â””â”€â”€ ...
  â”‚
  â–¼ ç“¶é¢ˆå±‚
  â”œâ”€â”€ ResBlock1D + FiLM
  â””â”€â”€ VariateCrossAttention (ä¸zäº¤äº’)
  â”‚
  â–¼ è§£ç å™¨ (4ä¸ªUpBlock)
  â”œâ”€â”€ ä¸Šé‡‡æ · + æ‹¼æ¥è·³è·ƒè¿æ¥
  â”œâ”€â”€ ResBlock1D + FiLM
  â””â”€â”€ VariateCrossAttention
  â”‚
  â–¼ è¾“å‡ºå·ç§¯
out [B, N, pred_len]
```

#### FiLM è°ƒåˆ¶æœºåˆ¶

**Feature-wise Linear Modulation** æ˜¯æ¡ä»¶æ³¨å…¥çš„æ ¸å¿ƒ:

```python
# æ•°å­¦è¡¨è¾¾
output = Î³ * input + Î²

# å®ç°ç»†èŠ‚
class FiLMLayer(nn.Module):
    def __init__(self, cond_dim, hidden_dim):
        self.gamma = nn.Linear(cond_dim, hidden_dim)
        self.beta = nn.Linear(cond_dim, hidden_dim)
        
        # é‡è¦åˆå§‹åŒ–
        nn.init.ones_(self.gamma.weight)  # Î³åˆå§‹åŒ–ä¸º1
        nn.init.zeros_(self.gamma.bias)   # Î³åç½®åˆå§‹åŒ–ä¸º0
        nn.init.zeros_(self.beta.weight)  # Î²åˆå§‹åŒ–ä¸º0
        nn.init.zeros_(self.beta.bias)    # Î²åç½®åˆå§‹åŒ–ä¸º0
    
    def forward(self, h, cond):
        # h: [B, C, T], cond: [B, cond_dim]
        gamma = self.gamma(cond).unsqueeze(-1)  # [B, C, 1]
        beta = self.beta(cond).unsqueeze(-1)    # [B, C, 1]
        return gamma * h + beta
```

#### å˜é‡äº¤å‰æ³¨æ„åŠ›

**VariateCrossAttention** å®ç°ç²¾ç»†åŒ–çš„å˜é‡çº§æ¡ä»¶èåˆ:

```python
class VariateCrossAttention(nn.Module):
    def forward(self, x, z):
        # x: [B, C, T] - å»å™ªç‰¹å¾ (Query)
        # z: [B, N, d_model] - ç¼–ç å™¨ç‰¹å¾ (Key/Value)
        
        # 1. ç»´åº¦è°ƒæ•´
        x_t = x.permute(0, 2, 1)  # [B, T, C]
        
        # 2. å¤šå¤´æ³¨æ„åŠ›
        Q = self.q_proj(x_t)       # [B, T, C]
        K = self.k_proj(z)         # [B, N, C]
        V = self.v_proj(z)         # [B, N, C]
        
        # 3. æ³¨æ„åŠ›è®¡ç®—
        attn = softmax(QK^T / âˆšd)  # [B, T, N]
        out = attn @ V             # [B, T, C]
        
        # 4. æ®‹å·®è¿æ¥ + å±‚å½’ä¸€åŒ–
        return self.norm(x_t + self.out_proj(out)).permute(0, 2, 1)
```

---

## ğŸ§® æ•°å­¦åŸç†

### æ‰©æ•£è¿‡ç¨‹

#### å‰å‘æ‰©æ•£ (åŠ å™ªè¿‡ç¨‹)

ç»™å®šå¹²å‡€æ•°æ® $x_0 \sim q(x)$ï¼Œé€æ­¥æ·»åŠ é«˜æ–¯å™ªå£°:

$$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t \mathbf{I})$$

å…¶ä¸­ $\beta_t \in (0,1)$ æ˜¯å™ªå£°è°ƒåº¦å‚æ•°ã€‚

é€šè¿‡é‡å‚æ•°åŒ–æŠ€å·§ï¼Œå¯ä»¥ç›´æ¥ä» $x_0$ é‡‡æ · $x_t$:

$$\begin{aligned}
\alpha_t &= 1 - \beta_t \\
\bar{\alpha}_t &= \prod_{s=1}^{t} \alpha_s \\
q(x_t | x_0) &= \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t) \mathbf{I}) \\
x_t &= \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, \mathbf{I})
\end{aligned}$$

#### é€†å‘æ‰©æ•£ (å»å™ªè¿‡ç¨‹)

è®­ç»ƒç¥ç»ç½‘ç»œ $p_\theta$ æ¥è¿‘ä¼¼ $q(x_{t-1} | x_t)$:

$$p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

### å‚æ•°åŒ–ç­–ç•¥

#### 1. xâ‚€-Prediction (ç›´æ¥é¢„æµ‹)

ç›´æ¥é¢„æµ‹å¹²å‡€æ•°æ® $x_0$:

$$\epsilon_\theta(x_t, t, z) = x_t - \sqrt{\bar{\alpha}_t} \cdot f_\theta(x_t, t, z)$$

å…¶ä¸­ $f_\theta$ é¢„æµ‹ $x_0$ã€‚

**ä¼˜åŠ¿**: ç›´è§‚ï¼Œæ”¶æ•›æ€§è´¨å¥½
**åŠ£åŠ¿**: æ—©æœŸæ—¶é—´æ­¥ä¿¡å™ªæ¯”ä½ï¼Œéœ€è¦clampç¨³å®š

#### 2. Îµ-Prediction (å™ªå£°é¢„æµ‹)

é¢„æµ‹æ·»åŠ çš„å™ªå£° $\epsilon$:

$$\epsilon_\theta(x_t, t, z) = f_\theta(x_t, t, z)$$

**ä¼˜åŠ¿**: DDPMæ ‡å‡†æ–¹æ³•
**åŠ£åŠ¿**: åæœŸæ—¶é—´æ­¥ä¿¡å™ªæ¯”ä½

#### 3. v-Prediction (é€Ÿåº¦é¢„æµ‹) â­

é¢„æµ‹é€Ÿåº¦å‚æ•° $v$:

$$\begin{aligned}
v &= \sqrt{\bar{\alpha}_t} \cdot \epsilon - \sqrt{1-\bar{\alpha}_t} \cdot x_0 \\
f_\theta(x_t, t, z) &= v
\end{aligned}$$

è½¬æ¢å…³ç³»:
$$\begin{aligned}
x_0 &= \sqrt{\bar{\alpha}_t} \cdot x_t - \sqrt{1-\bar{\alpha}_t} \cdot v \\
\epsilon &= \sqrt{1-\bar{\alpha}_t} \cdot x_t + \sqrt{\bar{\alpha}_t} \cdot v
\end{aligned}$$

**ä¼˜åŠ¿**: 
- æ‰€æœ‰æ—¶é—´æ­¥ä¿¡å™ªæ¯”å¹³è¡¡
- æ— éœ€clampç¨³å®šé¢„æµ‹
- æ›´å¥½çš„æ¢¯åº¦æµ

### æ¡ä»¶æœºåˆ¶

#### æ¡ä»¶æ³¨å…¥

iTransformerç‰¹å¾ $z$ ä½œä¸ºæ¡ä»¶æŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹:

$$\text{cond} = \text{ConditionProjector}(z, t_{\text{emb}})$$

å…¶ä¸­ $t_{\text{emb}}$ æ˜¯æ—¶é—´æ­¥çš„æ­£å¼¦ä½ç½®ç¼–ç ã€‚

#### FiLM è°ƒåˆ¶

æ¡ä»¶é€šè¿‡FiLMå±‚æ³¨å…¥U-Netçš„æ¯ä¸ªæ®‹å·®å—:

$$\text{output} = \gamma(\text{cond}) \cdot \text{input} + \beta(\text{cond})$$

#### äº¤å‰æ³¨æ„åŠ›

åœ¨ç“¶é¢ˆå±‚å’Œè§£ç å™¨ä¸­ï¼Œå»å™ªç‰¹å¾ä¸ç¼–ç å™¨ç‰¹å¾è¿›è¡Œäº¤å‰æ³¨æ„åŠ›:

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right)V$$

å…¶ä¸­ $Q$ æ¥è‡ªå»å™ªç‰¹å¾ï¼Œ$K, V$ æ¥è‡ªç¼–ç å™¨ç‰¹å¾ $z$ã€‚

---

## ğŸ“ è®­ç»ƒç­–ç•¥

### ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ (æ¨è)

#### è¯¾ç¨‹å­¦ä¹ æƒé‡è°ƒåº¦

```python
def _get_loss_weights(self, epoch):
    """
    ä¿®å¤ç‰ˆè¯¾ç¨‹å­¦ä¹ ï¼šå›ºå®šÎ±=0.8ï¼Œç¡®ä¿ç‚¹é¢„æµ‹æ€§èƒ½ä¼˜å…ˆ
    """
    alpha = 0.8  # MSEæŸå¤±æƒé‡
    beta = 0.2   # æ‰©æ•£æŸå¤±æƒé‡
    return alpha, beta
```

**è®¾è®¡ç†å¿µ**:
- å‰æœŸä»¥MSEä¸ºä¸»ï¼Œç¡®ä¿åŸºç¡€ç‚¹é¢„æµ‹èƒ½åŠ›
- åæœŸå¼•å…¥æ‰©æ•£æŸå¤±ï¼Œå­¦ä¹ ä¸ç¡®å®šæ€§å»ºæ¨¡
- å›ºå®šæƒé‡é¿å…æ€§èƒ½æ³¢åŠ¨

#### åˆ†ç»„å­¦ä¹ ç‡

```python
param_groups = [
    {'params': self.model.enc_embedding.parameters(), 'lr': lr},
    {'params': self.model.encoder.parameters(), 'lr': lr},
    {'params': self.model.projection.parameters(), 'lr': lr},
    {'params': self.model.denoise_net.parameters(), 'lr': lr},
    {'params': self.model.output_normalizer.parameters(), 'lr': lr},
]
```

### ä¸¤é˜¶æ®µè®­ç»ƒ (ç»å…¸)

#### Stage 1: Backboneé¢„çƒ­

```python
# åªè®­ç»ƒbackboneå‚æ•°
backbone_params = list(self.model.enc_embedding.parameters()) + \
                  list(self.model.encoder.parameters()) + \
                  list(self.model.projection.parameters())

# æŸå¤±: çº¯MSE
loss = F.mse_loss(y_det, y_true)
```

#### Stage 2: è”åˆè®­ç»ƒ

```python
# å†»ç»“ç¼–ç å™¨
self.model.freeze_encoder()

# åˆ†ç»„å­¦ä¹ ç‡
param_groups = [
    {'params': self.model.projection.parameters(), 'lr': stage2_lr},
    {'params': self.model.denoise_net.parameters(), 'lr': stage2_lr * 10},
    {'params': self.model.output_normalizer.parameters(), 'lr': stage2_lr * 10},
]

# æ··åˆæŸå¤±
loss = Î» * loss_mse + (1-Î») * loss_diff
```

### æŸå¤±å‡½æ•°

#### ç¡®å®šæ€§æŸå¤± (MSE)

$$\mathcal{L}_{\text{MSE}} = \frac{1}{B \cdot T \cdot N} \sum_{i=1}^{B} \sum_{t=1}^{T} \sum_{n=1}^{N} (y_{\text{det}}^{(i,t,n)} - y_{\text{true}}^{(i,t,n)})^2$$

#### æ‰©æ•£æŸå¤±

æ ¹æ®å‚æ•°åŒ–ç±»å‹é€‰æ‹©ç›®æ ‡:

```python
if parameterization == "x0":
    target = y_norm  # é¢„æµ‹å¹²å‡€æ•°æ®
elif parameterization == "epsilon":
    target = noise   # é¢„æµ‹å™ªå£°
elif parameterization == "v":
    target = sqrt_alpha_cumprod * noise - sqrt_one_minus_alpha_cumprod * y_norm

loss_diff = F.mse_loss(pred, target)
```

#### æ€»æŸå¤±

$$\mathcal{L}_{\text{total}} = \alpha \cdot \mathcal{L}_{\text{MSE}} + \beta \cdot \mathcal{L}_{\text{diff}}$$

---

## âš™ï¸ å®ç°ç»†èŠ‚

### æ•°å€¼ç¨³å®šæ€§

#### æ®‹å·®å½’ä¸€åŒ–

```python
class ResidualNormalizer(nn.Module):
    def normalize(self, residual, update_stats=True):
        if update_stats and self.training:
            # æ‰¹æ¬¡ç»Ÿè®¡
            batch_mean = residual.mean(dim=(0, 1), keepdim=True)
            batch_std = residual.std(dim=(0, 1), keepdim=True) + self.eps
            
            # EMAæ›´æ–°
            self.running_mean = (1 - momentum) * self.running_mean + momentum * batch_mean
            self.running_std = (1 - momentum) * self.running_std + momentum * batch_std
            
            return (residual - batch_mean) / batch_std
        else:
            # ä½¿ç”¨è¿è¡Œç»Ÿè®¡
            return (residual - self.running_mean) / self.running_std
```

#### Clampç¨³å®šåŒ–

```python
# åªå¯¹x0å‚æ•°åŒ–éœ€è¦clamp
if self.parameterization == 'x0':
    x0_pred = torch.clamp(x0_pred, -3.0, 3.0)
```

### å†…å­˜ä¼˜åŒ–

#### AMPæ··åˆç²¾åº¦

```python
# è®­ç»ƒæ—¶
with torch.cuda.amp.autocast():
    loss, loss_dict = self.model.forward_loss(...)
    
self.scaler.scale(loss).backward()
self.scaler.unscale_(optimizer)
torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
self.scaler.step(optimizer)
self.scaler.update()
```

#### åˆ†å—é‡‡æ ·

```python
def sample_chunked(self, z, n_samples=1, chunk_size=10):
    all_samples = []
    for i in range(0, n_samples, chunk_size):
        chunk_n = min(chunk_size, n_samples - i)
        samples = self.sample_ddpm_x0_batch(z, chunk_n)
        all_samples.append(samples)
    return torch.cat(all_samples, dim=0)
```

### é‡‡æ ·ç­–ç•¥

#### DDPMé‡‡æ · (å®Œæ•´)

```python
def sample_ddpm(self, z, n_samples=1):
    for t in reversed(range(self.timesteps)):
        # æ¨¡å‹é¢„æµ‹
        model_output = self.denoise_net(x, t_batch, z)
        x0_pred = self.predict_x0_from_output(model_output, x, t_batch)
        
        # æ¨å¯¼å™ªå£°é¢„æµ‹
        noise_pred = (x - sqrt(alpha_t) * x0_pred) / sqrt(1 - alpha_t)
        
        # DDPMæ›´æ–°
        mean = (1/sqrt(alpha_t)) * (x - (beta_t/sqrt(1-alpha_bar_t)) * noise_pred)
        
        if t > 0:
            x = mean + sqrt(beta_t) * noise
        else:
            x = mean
```

#### DDIMé‡‡æ · (åŠ é€Ÿ)

```python
def sample_ddim(self, z, n_samples=1, ddim_steps=50, eta=0.0):
    # åˆ›å»ºDDIMæ—¶é—´åºåˆ—
    step_size = self.timesteps // ddim_steps
    timesteps = list(range(0, self.timesteps, step_size))[::-1]
    
    for i, t in enumerate(timesteps):
        # é¢„æµ‹x0
        model_output = self.denoise_net(x, t_batch, z)
        x0_pred = self.predict_x0_from_output(model_output, x, t_batch)
        
        # DDIMæ›´æ–° (ç¡®å®šæ€§)
        alpha_t_prev = 1.0 if i == len(timesteps)-1 else self.alpha_cumprods[timesteps[i+1]]
        x = sqrt(alpha_t_prev) * x0_pred + sqrt(1 - alpha_t_prev) * noise_pred
```

#### Median-of-Means (MoM)

```python
def median_of_means(self, samples, k=10):
    """
    SimDiffæ–¹æ³•ï¼šMSEé™ä½8.3%
    """
    n_samples = samples.shape[0]
    group_size = n_samples // k
    group_means = []
    
    for i in range(k):
        start = i * group_size
        end = (i + 1) * group_size if i < k - 1 else n_samples
        group = samples[start:end]
        group_means.append(group.mean(dim=0))
    
    group_means = torch.stack(group_means, dim=0)
    return group_means.median(dim=0)[0]
```

---

## ğŸ“Š æ€§èƒ½åˆ†æ

### è®¡ç®—å¤æ‚åº¦

#### iTransformer Backbone
- **æ—¶é—´å¤æ‚åº¦**: $O(B \cdot N^2 \cdot d_model)$
- **ç©ºé—´å¤æ‚åº¦**: $O(B \cdot N \cdot d_model)$
- **æ³¨æ„**: $N$ æ˜¯å˜é‡æ•°ï¼Œé€šå¸¸ $N \ll seq_len$

#### 1D U-Net Denoiser
- **æ—¶é—´å¤æ‚åº¦**: $O(B \cdot C \cdot T \cdot \text{depth})$
- **ç©ºé—´å¤æ‚åº¦**: $O(B \cdot C \cdot T \cdot \text{depth})$
- **æ³¨æ„**: $C$ æ˜¯é€šé“æ•°ï¼Œ$T$ æ˜¯é¢„æµ‹é•¿åº¦

#### é‡‡æ ·å¤æ‚åº¦
- **DDPM**: $O(\text{timesteps} \cdot \text{forward_cost})$
- **DDIM**: $O(\text{ddim_steps} \cdot \text{forward_cost})$
- **Batché‡‡æ ·**: $O(\text{n_samples} \cdot \text{forward_cost})$

### æ˜¾å­˜ä½¿ç”¨åˆ†æ

#### è®­ç»ƒæ—¶æ˜¾å­˜
```python
# ä¸»è¦ç»„æˆ
backbone_features:    B * N * d_model * 4 bytes
unet_activations:    B * C_max * T * 4 bytes  
gradients:          ~2x parameters
optimizer_states:   ~2x parameters

# ä¼˜åŒ–ç­–ç•¥
--use_amp:          å‡å°‘50%æ˜¾å­˜
--chunk_size:       æ§åˆ¶é‡‡æ ·å³°å€¼
--batch_size:       çº¿æ€§å½±å“
```

#### æ¨ç†æ—¶æ˜¾å­˜
```python
# é‡‡æ ·æ˜¾å­˜ = batch_size * chunk_size * model_size
# ä¾‹å¦‚: B=32, chunk_size=10, model_size~100MB -> 32GB
```

### æ”¶æ•›æ€§åˆ†æ

#### å‚æ•°åŒ–å¯¹æ¯”

| å‚æ•°åŒ– | æ”¶æ•›é€Ÿåº¦ | ç¨³å®šæ€§ | æœ€ç»ˆè´¨é‡ | æ¨èåº¦ |
|--------|----------|--------|----------|--------|
| **v** | å¿« | é«˜ | é«˜ | â­â­â­â­â­ |
| **x0** | ä¸­ | ä¸­ | é«˜ | â­â­â­â­ |
| **Îµ** | æ…¢ | ä½ | ä¸­ | â­â­ |

#### è®­ç»ƒæ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | æ”¶æ•›é€Ÿåº¦ | æœ€ç»ˆæ€§èƒ½ | å®ç°å¤æ‚åº¦ | æ¨èåº¦ |
|------|----------|----------|------------|--------|
| **ç«¯åˆ°ç«¯** | å¿« | é«˜ | ä½ | â­â­â­â­â­ |
| **ä¸¤é˜¶æ®µ** | æ…¢ | ä¸­ | é«˜ | â­â­â­ |

---

## ğŸ§ª å®éªŒé…ç½®

### æ ‡å‡†é…ç½®

#### ETTh1æ•°æ®é›†
```bash
python run.py \
  --task_name diffusion_forecast \
  --model iTransformerDiffusionDirect \
  --data ETTh1 \
  --seq_len 96 --pred_len 96 \
  --enc_in 7 --dec_in 7 --c_out 7 \
  --d_model 64 --d_ff 64 \
  --e_layers 1 --d_layers 1 \
  --parameterization v \
  --training_mode end_to_end \
  --train_epochs 50 \
  --diffusion_steps 1000 \
  --n_samples 100 \
  --use_amp
```

#### ä½æ˜¾å­˜é…ç½® (8GB)
```bash
python run.py \
  # ... åŸºç¡€å‚æ•° ...
  --batch_size 16 \
  --diffusion_steps 100 \
  --n_samples 50 \
  --chunk_size 5 \
  --use_amp
```

#### å¿«é€Ÿå®éªŒé…ç½®
```bash
python run.py \
  # ... åŸºç¡€å‚æ•° ...
  --train_epochs 10 \
  --diffusion_steps 100 \
  --n_samples 10 \
  --use_ddim \
  --ddim_steps 10
```

### è¶…å‚æ•°è°ƒä¼˜

#### å­¦ä¹ ç‡è°ƒåº¦
```python
# æ¨èé…ç½®
learning_rate: 1e-4
weight_decay: 0.01
scheduler: CosineAnnealingLR
warmup_epochs: 10
```

#### æ‰©æ•£å‚æ•°
```python
# è´¨é‡vsé€Ÿåº¦æƒè¡¡
diffusion_steps: 1000  # é«˜è´¨é‡
diffusion_steps: 100   # å¿«é€Ÿ

beta_schedule: cosine  # æ¨è
beta_schedule: linear  # å¤‡é€‰
```

#### ç½‘ç»œæ¶æ„
```python
# å°æ¨¡å‹ (å¿«é€Ÿå®éªŒ)
d_model: 64
unet_channels: [32, 64, 128, 256]

# æ ‡å‡†æ¨¡å‹ (æ¨è)
d_model: 128  
unet_channels: [64, 128, 256, 512]

# å¤§æ¨¡å‹ (é«˜è´¨é‡)
d_model: 256
unet_channels: [128, 256, 512, 1024]
```

### è¯„ä¼°æŒ‡æ ‡

#### ç‚¹é¢„æµ‹æŒ‡æ ‡
```python
def point_metrics(pred, true):
    mse = F.mse_loss(pred, true)
    mae = F.l1_loss(pred, true)
    rmse = torch.sqrt(mse)
    return mse, mae, rmse
```

#### æ¦‚ç‡é¢„æµ‹æŒ‡æ ‡
```python
def crps_score(samples, y_true):
    """è¿ç»­æ’åæ¦‚ç‡åˆ†æ•°"""
    samples_sorted, _ = torch.sort(samples, dim=0)
    n_samples = samples.shape[0]
    
    crps = 0.0
    for i in range(n_samples):
        indicator = (samples_sorted[i] <= y_true).float()
        ecdf = (i + 1) / n_samples
        crps += (indicator - ecdf) ** 2
    
    return crps.mean() / n_samples

def calibration_score(samples, y_true, coverage_levels=[0.5, 0.9]):
    """æ ¡å‡†åº¦è¯„ä¼°"""
    results = {}
    n_samples = samples.shape[0]
    
    for level in coverage_levels:
        alpha = 1 - level
        lower_idx = int(n_samples * alpha / 2)
        upper_idx = int(n_samples * (1 - alpha / 2))
        
        samples_sorted, _ = torch.sort(samples, dim=0)
        lower = samples_sorted[lower_idx]
        upper = samples_sorted[upper_idx]
        
        within = ((y_true >= lower) & (y_true <= upper)).float().mean()
        results[f'coverage_{int(level*100)}'] = within
    
    return results
```

---

## ğŸš€ æ‰©å±•æ–¹å‘

### æ¨¡å‹æ¶æ„æ‰©å±•

#### 1. å¤šå°ºåº¦æ³¨æ„åŠ›
```python
class MultiScaleAttention(nn.Module):
    def __init__(self, d_model, n_heads, scales=[1, 2, 4]):
        super().__init__()
        self.scales = scales
        self.attentions = nn.ModuleList([
            AttentionLayer(d_model, n_heads) for _ in scales
        ])
    
    def forward(self, x):
        outputs = []
        for scale, attn in zip(self.scales, self.attentions):
            # å¤šå°ºåº¦ä¸‹é‡‡æ ·
            x_scaled = x[:, :, ::scale]
            out = attn(x_scaled)
            # ä¸Šé‡‡æ ·å›åŸå°ºå¯¸
            out = F.interpolate(out, size=x.shape[-1], mode='linear')
            outputs.append(out)
        return torch.mean(torch.stack(outputs), dim=0)
```

#### 2. é¢‘åŸŸå¢å¼º
```python
class FrequencyAwareLayer(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.freq_proj = nn.Linear(channels, channels)
        
    def forward(self, x):
        # æ—¶åŸŸ
        x_time = x
        
        # é¢‘åŸŸ
        x_freq = torch.fft.rfft(x, dim=-1)
        x_freq_mod = self.freq_proj(x_freq.real) + 1j * self.freq_proj(x_freq.imag)
        x_freq = torch.fft.irfft(x_freq_mod, n=x.shape[-1], dim=-1)
        
        # èåˆ
        return x_time + x_freq
```

#### 3. è‡ªé€‚åº”æ¡ä»¶æ³¨å…¥
```python
class AdaptiveConditioning(nn.Module):
    def __init__(self, d_model, cond_dim):
        super().__init__()
        self.condition_router = nn.Linear(d_model, cond_dim)
        self.condition_gate = nn.Linear(d_model, 1)
        
    def forward(self, x, z):
        # è‡ªé€‚åº”æ¡ä»¶è·¯ç”±
        route = torch.sigmoid(self.condition_router(z))
        gate = torch.sigmoid(self.condition_gate(z))
        
        # æ¡ä»¶è°ƒåˆ¶
        return x + gate * (route * z)
```

### è®­ç»ƒç­–ç•¥æ‰©å±•

#### 1. å¯¹æ¯”å­¦ä¹ å¢å¼º
```python
def contrastive_loss(samples, y_true, temperature=0.1):
    """å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæé«˜æ ·æœ¬è´¨é‡"""
    # æ­£æ ·æœ¬ï¼šæ¥è¿‘çœŸå®å€¼
    pos_sim = F.cosine_similarity(samples, y_true.unsqueeze(0), dim=-1)
    
    # è´Ÿæ ·æœ¬ï¼šè¿œç¦»å…¶ä»–æ ·æœ¬
    neg_sim = torch.cdist(samples, samples, p=2)
    
    # å¯¹æ¯”æŸå¤±
    loss = -torch.log(torch.exp(pos_sim / temperature) / 
                     torch.sum(torch.exp(neg_sim / temperature), dim=-1))
    
    return loss.mean()
```

#### 2. è¯¾ç¨‹å­¦ä¹ æ‰©å±•
```python
def advanced_curriculum(epoch, total_epochs):
    """é«˜çº§è¯¾ç¨‹å­¦ä¹ ç­–ç•¥"""
    progress = epoch / total_epochs
    
    # åŠ¨æ€æƒé‡è°ƒåº¦
    if progress < 0.3:
        # æ—©æœŸï¼šç‚¹é¢„æµ‹ä¸ºä¸»
        alpha, beta = 0.9, 0.1
    elif progress < 0.7:
        # ä¸­æœŸï¼šå¹³è¡¡
        alpha, beta = 0.7, 0.3
    else:
        # åæœŸï¼šæ¦‚ç‡å»ºæ¨¡ä¸ºä¸»
        alpha, beta = 0.5, 0.5
    
    # åŠ¨æ€æ‰©æ•£æ­¥æ•°
    diffusion_steps = int(100 + progress * 900)
    
    return alpha, beta, diffusion_steps
```

#### 3. å¤šä»»åŠ¡å­¦ä¹ 
```python
class MultiTaskLoss(nn.Module):
    def __init__(self, n_tasks):
        super().__init__()
        self.log_vars = nn.Parameter(torch.zeros(n_tasks))
        
    def forward(self, losses):
        """ä¸ç¡®å®šæ€§åŠ æƒçš„å¤šä»»åŠ¡æŸå¤±"""
        loss = 0
        for i, loss_i in enumerate(losses):
            precision = torch.exp(-self.log_vars[i])
            loss += precision * loss_i + self.log_vars[i]
        return loss
```

### åº”ç”¨åœºæ™¯æ‰©å±•

#### 1. å¤šå˜é‡é¢„æµ‹
```python
class MultivariateForecasting(nn.Module):
    def __init__(self, base_model, n_vars):
        super().__init__()
        self.base_model = base_model
        self.variate_heads = nn.ModuleList([
            nn.Linear(d_model, pred_len) for _ in range(n_vars)
        ])
    
    def forward(self, x):
        z = self.base_model.backbone_forward(x)
        outputs = []
        for i, head in enumerate(self.variate_heads):
            out = head(z[:, i, :])
            outputs.append(out)
        return torch.stack(outputs, dim=1)
```

#### 2. é•¿åºåˆ—é¢„æµ‹
```python
class LongSequenceForecasting(nn.Module):
    def __init__(self, base_model, chunk_size=96):
        super().__init__()
        self.base_model = base_model
        self.chunk_size = chunk_size
        
    def forward(self, x, pred_len):
        # åˆ†å—é¢„æµ‹é•¿åºåˆ—
        outputs = []
        for i in range(0, pred_len, self.chunk_size):
            chunk_pred_len = min(self.chunk_size, pred_len - i)
            chunk_output = self.base_model(x, pred_len=chunk_pred_len)
            outputs.append(chunk_output)
            # æ»‘åŠ¨çª—å£æ›´æ–°è¾“å…¥
            x = torch.cat([x[:, chunk_pred_len:, :], chunk_output], dim=1)
        return torch.cat(outputs, dim=1)
```

#### 3. åœ¨çº¿å­¦ä¹ 
```python
class OnlineLearning(nn.Module):
    def __init__(self, base_model, buffer_size=1000):
        super().__init__()
        self.base_model = base_model
        self.buffer = ReplayBuffer(buffer_size)
        
    def update(self, new_data):
        """åœ¨çº¿æ›´æ–°æ¨¡å‹"""
        # æ·»åŠ åˆ°ç»éªŒå›æ”¾
        self.buffer.add(new_data)
        
        # é‡‡æ ·è®­ç»ƒ
        batch = self.buffer.sample()
        loss = self.base_model.train_step(batch)
        
        return loss
```

### è¯„ä¼°æŒ‡æ ‡æ‰©å±•

#### 1. åˆ†å¸ƒè´¨é‡æŒ‡æ ‡
```python
def wasserstein_distance(samples, y_true):
    """Wassersteinè·ç¦»"""
    # æ’åº
    samples_sorted, _ = torch.sort(samples, dim=0)
    y_true_sorted, _ = torch.sort(y_true, dim=0)
    
    # è®¡ç®—Wasserstein-1è·ç¦»
    wasserstein = torch.mean(torch.abs(samples_sorted - y_true_sorted))
    return wasserstein

def energy_score(samples, y_true):
    """Energy Score"""
    n_samples = samples.shape[0]
    
    # æ ·æœ¬é—´è·ç¦»
    sample_distances = torch.cdist(samples, samples, p=2)
    energy_samples = torch.mean(sample_distances)
    
    # æ ·æœ¬ä¸çœŸå®å€¼è·ç¦»
    true_distances = torch.cdist(samples, y_true.unsqueeze(0), p=2)
    energy_true = torch.mean(true_distances)
    
    return energy_true - 0.5 * energy_samples
```

#### 2. æ—¶é—´åºåˆ—ç‰¹å®šæŒ‡æ ‡
```python
def temporal_calibration(samples, y_true, window_size=10):
    """æ—¶é—´çª—å£æ ¡å‡†åº¦"""
    calibrations = []
    
    for t in range(0, samples.shape[1], window_size):
        window_samples = samples[:, t:t+window_size, :]
        window_true = y_true[t:t+window_size, :]
        
        # çª—å£å†…æ ¡å‡†åº¦
        calib = calibration_score(window_samples, window_true)
        calibrations.append(calib)
    
    return calibrations

def trend_consistency(samples, y_true):
    """è¶‹åŠ¿ä¸€è‡´æ€§"""
    # è®¡ç®—è¶‹åŠ¿
    def compute_trend(series):
        return torch.diff(series, dim=-2).sign()
    
    sample_trends = compute_trend(samples)
    true_trend = compute_trend(y_true)
    
    # è¶‹åŠ¿ä¸€è‡´æ€§
    consistency = (sample_trends == true_trend.unsqueeze(0)).float().mean()
    return consistency
```

---

## ğŸ“ æ€»ç»“

iTransformerDiffusionDirect æ˜¯ä¸€ä¸ªè®¾è®¡ç²¾è‰¯çš„æ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

### ğŸ¯ æŠ€æœ¯åˆ›æ–°
1. **ç›´æ¥é¢„æµ‹ç­–ç•¥**: ç›¸æ¯”æ®‹å·®é¢„æµ‹ï¼Œè®­ç»ƒæ›´ç¨³å®šï¼Œæ”¶æ•›æ›´å¿«
2. **å¤šå‚æ•°åŒ–æ”¯æŒ**: v-predictionæä¾›æœ€ä½³è®­ç»ƒç¨³å®šæ€§
3. **ç«¯åˆ°ç«¯è®­ç»ƒ**: æ¢¯åº¦è¿é€šï¼Œæ€§èƒ½æ›´ä¼˜
4. **é«˜æ•ˆé‡‡æ ·**: DDIMåŠ é€Ÿï¼Œæ‰¹é‡å¹¶è¡Œï¼Œåˆ†å—å†…å­˜ç®¡ç†

### ğŸš€ å·¥ç¨‹ä¼˜åŠ¿
1. **æ˜¾å­˜ä¼˜åŒ–**: AMPæ··åˆç²¾åº¦ï¼ŒèŠ‚çœ30-50%æ˜¾å­˜
2. **æ•°å€¼ç¨³å®š**: æ®‹å·®å½’ä¸€åŒ–ï¼Œclampç¨³å®šåŒ–
3. **æ¨¡å—åŒ–è®¾è®¡**: ç»„ä»¶å¯å¤ç”¨ï¼Œæ˜“äºæ‰©å±•
4. **å®Œæ•´è¯„ä¼°**: ç‚¹é¢„æµ‹+æ¦‚ç‡é¢„æµ‹å…¨æ–¹ä½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½è¡¨ç°
1. **ç‚¹é¢„æµ‹ç²¾åº¦**: ä¸iTransformerç›¸å½“
2. **æ¦‚ç‡é¢„æµ‹è´¨é‡**: CRPSã€æ ¡å‡†åº¦ä¼˜ç§€
3. **è®­ç»ƒæ•ˆç‡**: ç«¯åˆ°ç«¯è®­ç»ƒæ”¶æ•›æ›´å¿«
4. **æ¨ç†é€Ÿåº¦**: DDIMé‡‡æ ·æå‡20å€

### ğŸ“ åº”ç”¨ä»·å€¼
1. **é‡‘èé¢„æµ‹**: è‚¡ä»·ã€é£é™©å»ºæ¨¡
2. **èƒ½æºé¢„æµ‹**: è´Ÿè·ã€å¯å†ç”Ÿèƒ½æº
3. **äº¤é€šé¢„æµ‹**: æµé‡ã€æ‹¥å µé¢„æµ‹
4. **æ°”è±¡é¢„æµ‹**: æ¸©åº¦ã€é™æ°´æ¦‚ç‡

è¿™ä¸ªæ¨¡å‹ä¸ºæ—¶é—´åºåˆ—é¢„æµ‹é¢†åŸŸæä¾›äº†ä¸€ä¸ªå¼ºæœ‰åŠ›çš„å·¥å…·ï¼Œæ—¢ä¿è¯äº†ç‚¹é¢„æµ‹çš„ç²¾åº¦ï¼Œåˆæä¾›äº†é«˜è´¨é‡çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæ˜¯ç†è®ºä¸å®è·µçš„å®Œç¾ç»“åˆã€‚