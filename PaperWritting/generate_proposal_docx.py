#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_proposal_docx.py - ç”Ÿæˆç¬¦åˆæ­¦æ±‰ç†å·¥å¤§å­¦æ ¼å¼è¦æ±‚çš„å¼€é¢˜æŠ¥å‘Š DOCX

æ ¼å¼è§„èŒƒï¼š
- é¡µé¢ï¼šA4ï¼Œé¡µè¾¹è·ä¸Š3.0cm/ä¸‹2.6cm/å·¦2.8cm/å³2.7cm
- å°é¢ï¼šå­¦æ ¡ååæ–‡ä¸­å®‹ä¸€å·ã€è¯¾é¢˜åé»‘ä½“äºŒå·ã€ä¿¡æ¯åæ–‡ä¸­å®‹ä¸‰å·
- ä¸€çº§æ ‡é¢˜ï¼šé»‘ä½“å°äºŒå·(18pt)å±…ä¸­
- äºŒçº§æ ‡é¢˜ï¼šé»‘ä½“ä¸‰å·(16pt)å·¦å¯¹é½
- ä¸‰çº§æ ‡é¢˜ï¼šé»‘ä½“å››å·(14pt)å·¦å¯¹é½
- æ­£æ–‡ï¼šå®‹ä½“å°å››å·(12pt)ï¼Œé¦–è¡Œç¼©è¿›2å­—ç¬¦
- å‚è€ƒæ–‡çŒ®ï¼šå®‹ä½“äº”å·(10.5pt)
- æ•°å­¦å…¬å¼ï¼šä½¿ç”¨ Word åŸç”Ÿ OMML æ ¼å¼
"""

from docx import Document
from docx.shared import Pt, Cm, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING
from docx.enum.table import WD_TABLE_ALIGNMENT
from docx.oxml.ns import qn, nsmap
from docx.oxml import OxmlElement
import os

# ========== OMML æ•°å­¦å…¬å¼è¾…åŠ©å‡½æ•° ==========

# OMML å‘½åç©ºé—´
OMML_NS = 'http://schemas.openxmlformats.org/officeDocument/2006/math'

def _omml(tag):
    """åˆ›å»º OMML å…ƒç´ """
    el = OxmlElement(f'm:{tag}')
    return el

def _omml_text(text):
    """åˆ›å»º OMML æ–‡æœ¬è¿è¡Œ <m:r><m:t>text</m:t></m:r>"""
    r = _omml('r')
    t = _omml('t')
    t.text = text
    r.append(t)
    return r

def _omml_sub(base, subscript):
    """åˆ›å»ºä¸‹æ ‡ base_subscript"""
    sSub = _omml('sSub')
    e = _omml('e')
    e.append(_omml_text(base))
    sub = _omml('sub')
    sub.append(_omml_text(subscript))
    sSub.append(e)
    sSub.append(sub)
    return sSub

def _omml_sup(base, superscript):
    """åˆ›å»ºä¸Šæ ‡ base^superscript"""
    sSup = _omml('sSup')
    e = _omml('e')
    e.append(_omml_text(base))
    sup = _omml('sup')
    sup.append(_omml_text(superscript))
    sSup.append(e)
    sSup.append(sup)
    return sSup

def _omml_subsup(base, subscript, superscript):
    """åˆ›å»ºä¸Šä¸‹æ ‡ base_subscript^superscript"""
    sSubSup = _omml('sSubSup')
    e = _omml('e')
    e.append(_omml_text(base))
    sub = _omml('sub')
    sub.append(_omml_text(subscript))
    sup = _omml('sup')
    sup.append(_omml_text(superscript))
    sSubSup.append(e)
    sSubSup.append(sub)
    sSubSup.append(sup)
    return sSubSup

def _omml_frac(num_text, den_text):
    """åˆ›å»ºåˆ†æ•° num/den"""
    f = _omml('f')
    num = _omml('num')
    num.append(_omml_text(num_text))
    den = _omml('den')
    den.append(_omml_text(den_text))
    f.append(num)
    f.append(den)
    return f

def _omml_sqrt(content_text):
    """åˆ›å»ºå¹³æ–¹æ ¹ âˆšcontent"""
    rad = _omml('rad')
    radPr = _omml('radPr')
    degHide = _omml('degHide')
    degHide.set(qn('m:val'), '1')
    radPr.append(degHide)
    rad.append(radPr)
    deg = _omml('deg')
    rad.append(deg)
    e = _omml('e')
    e.append(_omml_text(content_text))
    rad.append(e)
    return rad

def _omml_bar(content_text):
    """åˆ›å»ºä¸Šæ¨ªçº¿ xÌ„"""
    acc = _omml('acc')
    accPr = _omml('accPr')
    chr_el = _omml('chr')
    chr_el.set(qn('m:val'), 'Ì„')  # ç»„åˆç”¨æ¨ªçº¿
    accPr.append(chr_el)
    acc.append(accPr)
    e = _omml('e')
    e.append(_omml_text(content_text))
    acc.append(e)
    return acc

def _omml_bracket(content_elements, left='(', right=')'):
    """åˆ›å»ºå¸¦æ‹¬å·çš„è¡¨è¾¾å¼"""
    d = _omml('d')
    dPr = _omml('dPr')
    begChr = _omml('begChr')
    begChr.set(qn('m:val'), left)
    endChr = _omml('endChr')
    endChr.set(qn('m:val'), right)
    dPr.append(begChr)
    dPr.append(endChr)
    d.append(dPr)
    e = _omml('e')
    for el in content_elements:
        e.append(el)
    d.append(e)
    return d

def create_omath():
    """åˆ›å»º oMath å®¹å™¨"""
    return _omml('oMath')

def add_omath_to_para(para, omath):
    """å°† oMath æ·»åŠ åˆ°æ®µè½"""
    para._p.append(omath)

def add_text_run_to_para(para, text, cn_font='å®‹ä½“', en_font='Times New Roman', size_pt=12, bold=False):
    """å‘æ®µè½æ·»åŠ æ™®é€šæ–‡æœ¬è¿è¡Œ"""
    run = para.add_run(text)
    run.font.name = en_font
    run.font.size = Pt(size_pt)
    run.font.bold = bold
    r = run._element
    rPr = r.get_or_add_rPr()
    rFonts = rPr.find(qn('w:rFonts'))
    if rFonts is None:
        rFonts = OxmlElement('w:rFonts')
        rPr.insert(0, rFonts)
    rFonts.set(qn('w:eastAsia'), cn_font)
    rFonts.set(qn('w:ascii'), en_font)
    rFonts.set(qn('w:hAnsi'), en_font)
    return run


# ========== ç‰¹å®šå…¬å¼æ„å»ºå‡½æ•° ==========

def build_forward_diffusion_formula():
    """æ„å»ºå‰å‘æ‰©æ•£å…¬å¼: q(x_t|x_{t-1}) = N(x_t; âˆš(1-Î²_t)x_{t-1}, Î²_t I)"""
    omath = create_omath()

    # q(x_t|x_{t-1})
    omath.append(_omml_text('q'))
    d1 = _omml('d')  # æ‹¬å·
    dPr1 = _omml('dPr')
    d1.append(dPr1)
    e1 = _omml('e')
    e1.append(_omml_sub('x', 't'))
    e1.append(_omml_text('|'))
    e1.append(_omml_sub('x', 't-1'))
    d1.append(e1)
    omath.append(d1)

    # =
    omath.append(_omml_text(' = '))

    # N(...)
    omath.append(_omml_text('ğ’©'))
    d2 = _omml('d')
    dPr2 = _omml('dPr')
    d2.append(dPr2)
    e2 = _omml('e')
    e2.append(_omml_sub('x', 't'))
    e2.append(_omml_text('; '))
    e2.append(_omml_sqrt('1-Î²'))
    e2.append(_omml_sub('x', 't-1'))
    e2.append(_omml_text(', '))
    e2.append(_omml_sub('Î²', 't'))
    e2.append(_omml_text('I'))
    d2.append(e2)
    omath.append(d2)

    return omath

def build_reverse_diffusion_formula():
    """æ„å»ºé€†å‘å»å™ªå…¬å¼: p_Î¸(x_{t-1}|x_t) = N(x_{t-1}; Î¼_Î¸(x_t,t), Î£_Î¸(x_t,t))"""
    omath = create_omath()

    # p_Î¸(x_{t-1}|x_t)
    omath.append(_omml_sub('p', 'Î¸'))
    d1 = _omml('d')
    dPr1 = _omml('dPr')
    d1.append(dPr1)
    e1 = _omml('e')
    e1.append(_omml_sub('x', 't-1'))
    e1.append(_omml_text('|'))
    e1.append(_omml_sub('x', 't'))
    d1.append(e1)
    omath.append(d1)

    # =
    omath.append(_omml_text(' = '))

    # N(...)
    omath.append(_omml_text('ğ’©'))
    d2 = _omml('d')
    dPr2 = _omml('dPr')
    d2.append(dPr2)
    e2 = _omml('e')
    e2.append(_omml_sub('x', 't-1'))
    e2.append(_omml_text('; '))
    e2.append(_omml_sub('Î¼', 'Î¸'))
    d3 = _omml('d')
    dPr3 = _omml('dPr')
    d3.append(dPr3)
    e3 = _omml('e')
    e3.append(_omml_sub('x', 't'))
    e3.append(_omml_text(',t'))
    d3.append(e3)
    e2.append(d3)
    e2.append(_omml_text(', '))
    e2.append(_omml_sub('Î£', 'Î¸'))
    d4 = _omml('d')
    dPr4 = _omml('dPr')
    d4.append(dPr4)
    e4 = _omml('e')
    e4.append(_omml_sub('x', 't'))
    e4.append(_omml_text(',t'))
    d4.append(e4)
    e2.append(d4)
    d2.append(e2)
    omath.append(d2)

    return omath

def build_v_prediction_formula():
    """æ„å»º v-prediction å…¬å¼: v = âˆšÎ±Ì…_t Â· Îµ - âˆš(1-Î±Ì…_t) Â· x_0"""
    omath = create_omath()

    # v =
    omath.append(_omml_text('v = '))

    # âˆšÎ±Ì…_t
    rad1 = _omml('rad')
    radPr1 = _omml('radPr')
    degHide1 = _omml('degHide')
    degHide1.set(qn('m:val'), '1')
    radPr1.append(degHide1)
    rad1.append(radPr1)
    deg1 = _omml('deg')
    rad1.append(deg1)
    e1 = _omml('e')
    e1.append(_omml_sub('Î±Ì…', 't'))
    rad1.append(e1)
    omath.append(rad1)

    # Â· Îµ
    omath.append(_omml_text(' Â· Îµ - '))

    # âˆš(1-Î±Ì…_t)
    rad2 = _omml('rad')
    radPr2 = _omml('radPr')
    degHide2 = _omml('degHide')
    degHide2.set(qn('m:val'), '1')
    radPr2.append(degHide2)
    rad2.append(radPr2)
    deg2 = _omml('deg')
    rad2.append(deg2)
    e2 = _omml('e')
    e2.append(_omml_text('1-'))
    e2.append(_omml_sub('Î±Ì…', 't'))
    rad2.append(e2)
    omath.append(rad2)

    # Â· x_0
    omath.append(_omml_text(' Â· '))
    omath.append(_omml_sub('x', '0'))

    return omath

def build_dimension_formula(var_name, dims):
    """æ„å»ºç»´åº¦å…¬å¼ï¼Œå¦‚ X âˆˆ â„^{BÃ—TÃ—N}"""
    omath = create_omath()
    omath.append(_omml_text(var_name + ' âˆˆ '))
    omath.append(_omml_sup('â„', dims))
    return omath

def build_noise_pred_formula():
    """æ„å»ºå™ªå£°é¢„æµ‹ç½‘ç»œå…¬å¼: Îµ_Î¸(x_t, t)"""
    omath = create_omath()
    omath.append(_omml_sub('Îµ', 'Î¸'))
    d = _omml('d')
    dPr = _omml('dPr')
    d.append(dPr)
    e = _omml('e')
    e.append(_omml_sub('x', 't'))
    e.append(_omml_text(', t'))
    d.append(e)
    omath.append(d)
    return omath

def build_film_formula():
    """æ„å»º FiLM å…¬å¼: h' = Î³ âŠ™ h + Î²"""
    omath = create_omath()
    omath.append(_omml_text("h' = Î³ âŠ™ h + Î²"))
    return omath


class ProposalGenerator:
    """å¼€é¢˜æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.doc = Document()
        self._setup_page()

    def _setup_page(self):
        """è®¾ç½®é¡µé¢å¸ƒå±€ï¼šA4çº¸ï¼ŒæŒ‡å®šé¡µè¾¹è·"""
        section = self.doc.sections[0]
        section.page_width = Cm(21)
        section.page_height = Cm(29.7)
        section.top_margin = Cm(3.0)
        section.bottom_margin = Cm(2.6)
        section.left_margin = Cm(2.8)
        section.right_margin = Cm(2.7)

    def _set_run_font(self, run, cn_font, en_font, size_pt, bold=False):
        """è®¾ç½® run çš„ä¸­è‹±æ–‡å­—ä½“"""
        run.font.name = en_font
        run.font.size = Pt(size_pt)
        run.font.bold = bold

        # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé€šè¿‡ XML æ“ä½œï¼‰
        r = run._element
        rPr = r.get_or_add_rPr()

        # æŸ¥æ‰¾æˆ–åˆ›å»º rFonts å…ƒç´ 
        rFonts = rPr.find(qn('w:rFonts'))
        if rFonts is None:
            rFonts = OxmlElement('w:rFonts')
            rPr.insert(0, rFonts)

        rFonts.set(qn('w:eastAsia'), cn_font)
        rFonts.set(qn('w:ascii'), en_font)
        rFonts.set(qn('w:hAnsi'), en_font)

    def _set_paragraph_format(self, para, alignment=WD_ALIGN_PARAGRAPH.LEFT,
                               first_indent=None, line_spacing=1.5,
                               space_before=0, space_after=0):
        """è®¾ç½®æ®µè½æ ¼å¼"""
        para.alignment = alignment
        pf = para.paragraph_format

        if first_indent is not None:
            pf.first_line_indent = Cm(first_indent)

        pf.line_spacing = line_spacing
        pf.space_before = Pt(space_before)
        pf.space_after = Pt(space_after)

    # ========== å°é¢ç›¸å…³æ–¹æ³• ==========

    def add_cover(self, title, student_name="", class_name="", advisor="", date=""):
        """æ·»åŠ å°é¢"""
        # ç©ºè¡Œï¼ˆè°ƒæ•´ä½ç½®ï¼‰
        for _ in range(3):
            para = self.doc.add_paragraph()
            self._set_paragraph_format(para, space_after=0)

        # å­¦æ ¡åç§°ï¼šåæ–‡ä¸­å®‹ä¸€å·(26pt)å±…ä¸­
        para = self.doc.add_paragraph()
        run = para.add_run("æ­¦æ±‰ç†å·¥å¤§å­¦")
        self._set_run_font(run, 'åæ–‡ä¸­å®‹', 'Times New Roman', 26, bold=False)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER, space_after=6)

        # æ–‡æ¡£ç±»å‹ï¼šåæ–‡ä¸­å®‹ä¸€å·(26pt)å±…ä¸­
        para = self.doc.add_paragraph()
        run = para.add_run("å¼€é¢˜æŠ¥å‘Š")
        self._set_run_font(run, 'åæ–‡ä¸­å®‹', 'Times New Roman', 26, bold=False)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER, space_after=24)

        # ç©ºè¡Œ
        for _ in range(2):
            para = self.doc.add_paragraph()
            self._set_paragraph_format(para, space_after=0)

        # è¯¾é¢˜åç§°ï¼šé»‘ä½“äºŒå·(22pt)å±…ä¸­
        para = self.doc.add_paragraph()
        run = para.add_run(title)
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 22, bold=True)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER, space_before=24, space_after=48)

        # ç©ºè¡Œ
        for _ in range(4):
            para = self.doc.add_paragraph()
            self._set_paragraph_format(para, space_after=0)

        # ä¿¡æ¯å­—æ®µï¼šåæ–‡ä¸­å®‹ä¸‰å·(16pt)
        info_fields = [
            ("å­¦ç”Ÿå§“å", student_name),
            ("ä¸“ä¸šç­çº§", class_name),
            ("æŒ‡å¯¼æ•™å¸ˆ", advisor),
            ("å®Œæˆæ—¶é—´", date),
        ]

        for label, value in info_fields:
            para = self.doc.add_paragraph()
            run = para.add_run(f"{label}ï¼š    {value}    ")
            self._set_run_font(run, 'åæ–‡ä¸­å®‹', 'Times New Roman', 16, bold=False)
            self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER, space_before=6, space_after=6)

        # åˆ†é¡µ
        self.doc.add_page_break()

    # ========== æ ‡é¢˜æ–¹æ³• ==========

    def add_heading1(self, text):
        """ä¸€çº§æ ‡é¢˜ï¼šé»‘ä½“å°äºŒå·(18pt)å±…ä¸­"""
        para = self.doc.add_paragraph()
        run = para.add_run(text)
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 18, bold=True)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER,
                                   space_before=12, space_after=12)
        return para

    def add_heading2(self, text):
        """äºŒçº§æ ‡é¢˜ï¼šé»‘ä½“ä¸‰å·(16pt)å·¦å¯¹é½"""
        para = self.doc.add_paragraph()
        run = para.add_run(text)
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 16, bold=True)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.LEFT,
                                   space_before=12, space_after=6)
        return para

    def add_heading3(self, text):
        """ä¸‰çº§æ ‡é¢˜ï¼šé»‘ä½“å››å·(14pt)å·¦å¯¹é½"""
        para = self.doc.add_paragraph()
        run = para.add_run(text)
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 14, bold=True)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.LEFT,
                                   space_before=6, space_after=3)
        return para

    # ========== æ­£æ–‡æ–¹æ³• ==========

    def add_body_text(self, text, first_indent=True):
        """æ­£æ–‡ï¼šå®‹ä½“å°å››å·(12pt)ï¼Œé¦–è¡Œç¼©è¿›2å­—ç¬¦"""
        para = self.doc.add_paragraph()
        run = para.add_run(text)
        self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 12, bold=False)
        indent = 0.74 if first_indent else None
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.JUSTIFY,
                                   first_indent=indent, line_spacing=1.5)
        return para

    def add_body_text_bold(self, label, text):
        """æ­£æ–‡ï¼ˆå¸¦åŠ ç²—æ ‡ç­¾ï¼‰"""
        para = self.doc.add_paragraph()
        run = para.add_run(label)
        self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 12, bold=True)
        run = para.add_run(text)
        self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 12, bold=False)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.JUSTIFY,
                                   first_indent=0.74, line_spacing=1.5)
        return para

    def add_body_with_formula(self, content_parts, first_indent=True):
        """
        æ·»åŠ åŒ…å«æ•°å­¦å…¬å¼çš„æ­£æ–‡æ®µè½

        content_parts: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºï¼š
            - å­—ç¬¦ä¸²ï¼šæ™®é€šæ–‡æœ¬
            - ('formula', omath): æ•°å­¦å…¬å¼
            - ('bold', text): åŠ ç²—æ–‡æœ¬
        """
        para = self.doc.add_paragraph()
        indent = 0.74 if first_indent else None
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.JUSTIFY,
                                   first_indent=indent, line_spacing=1.5)

        for part in content_parts:
            if isinstance(part, str):
                # æ™®é€šæ–‡æœ¬
                add_text_run_to_para(para, part, 'å®‹ä½“', 'Times New Roman', 12, False)
            elif isinstance(part, tuple):
                if part[0] == 'formula':
                    # æ•°å­¦å…¬å¼
                    add_omath_to_para(para, part[1])
                elif part[0] == 'bold':
                    # åŠ ç²—æ–‡æœ¬
                    add_text_run_to_para(para, part[1], 'å®‹ä½“', 'Times New Roman', 12, True)

        return para

    def add_formula_paragraph(self, omath, centered=True):
        """æ·»åŠ ç‹¬ç«‹çš„å…¬å¼æ®µè½ï¼ˆå…¬å¼å•ç‹¬ä¸€è¡Œï¼‰"""
        para = self.doc.add_paragraph()
        alignment = WD_ALIGN_PARAGRAPH.CENTER if centered else WD_ALIGN_PARAGRAPH.LEFT
        self._set_paragraph_format(para, alignment, line_spacing=1.5,
                                   space_before=6, space_after=6)
        add_omath_to_para(para, omath)
        return para

    # ========== ç‰¹æ®Šå†…å®¹ ==========

    def add_abstract(self, title, content, keywords):
        """æ·»åŠ æ‘˜è¦"""
        para = self.doc.add_paragraph()
        run = para.add_run(title)
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 18, bold=True)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.CENTER,
                                   space_before=12, space_after=12)

        self.add_body_text(content)

        para = self.doc.add_paragraph()
        run = para.add_run("å…³é”®è¯ï¼š")
        self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 14, bold=True)
        run = para.add_run(keywords)
        self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 12, bold=False)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.LEFT,
                                   space_before=12, space_after=12)

        self.doc.add_page_break()

    def add_reference(self, text):
        """å‚è€ƒæ–‡çŒ®æ¡ç›®ï¼šå®‹ä½“äº”å·(10.5pt)"""
        para = self.doc.add_paragraph()
        run = para.add_run(text)
        self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 10.5, bold=False)
        self._set_paragraph_format(para, WD_ALIGN_PARAGRAPH.LEFT,
                                   line_spacing=1.25, space_after=3)
        return para

    def add_schedule_table(self, schedule_data):
        """æ·»åŠ è¿›åº¦å®‰æ’è¡¨æ ¼"""
        table = self.doc.add_table(rows=1, cols=3)
        table.alignment = WD_TABLE_ALIGNMENT.CENTER

        header_cells = table.rows[0].cells
        headers = ['é˜¶æ®µ', 'å‘¨æ¬¡', 'ä¸»è¦ä»»åŠ¡ä¸é¢„æœŸæˆæœ']
        for i, header in enumerate(headers):
            cell = header_cells[i]
            para = cell.paragraphs[0]
            run = para.add_run(header)
            self._set_run_font(run, 'é»‘ä½“', 'Times New Roman', 12, bold=True)
            para.alignment = WD_ALIGN_PARAGRAPH.CENTER

        for stage, week, task in schedule_data:
            row_cells = table.add_row().cells
            for i, text in enumerate([stage, week, task]):
                cell = row_cells[i]
                para = cell.paragraphs[0]
                run = para.add_run(text)
                self._set_run_font(run, 'å®‹ä½“', 'Times New Roman', 12, bold=False)
                para.alignment = WD_ALIGN_PARAGRAPH.CENTER if i < 2 else WD_ALIGN_PARAGRAPH.LEFT

        self._set_table_border(table)
        return table

    def _set_table_border(self, table):
        """è®¾ç½®è¡¨æ ¼è¾¹æ¡†"""
        tbl = table._tbl
        tblPr = tbl.tblPr if tbl.tblPr is not None else OxmlElement('w:tblPr')

        tblBorders = OxmlElement('w:tblBorders')
        for border_name in ['top', 'left', 'bottom', 'right', 'insideH', 'insideV']:
            border = OxmlElement(f'w:{border_name}')
            border.set(qn('w:val'), 'single')
            border.set(qn('w:sz'), '4')
            border.set(qn('w:color'), '000000')
            tblBorders.append(border)

        tblPr.append(tblBorders)
        if tbl.tblPr is None:
            tbl.insert(0, tblPr)

    def save(self, filepath):
        """ä¿å­˜æ–‡æ¡£"""
        self.doc.save(filepath)
        print(f"æ–‡æ¡£å·²ä¿å­˜ï¼š{filepath}")


def generate_proposal():
    """ç”Ÿæˆå¼€é¢˜æŠ¥å‘Š"""
    gen = ProposalGenerator()

    # ========== å°é¢ ==========
    gen.add_cover(
        title="åŸºäºæ‰©æ•£æœºåˆ¶èåˆçš„æ—¶é—´åºåˆ—æ¦‚ç‡é¢„æµ‹ç ”ç©¶",
        student_name="",
        class_name="",
        advisor="",
        date=""
    )

    # ========== æ‘˜è¦ ==========
    abstract_content = '''æ—¶é—´åºåˆ—é¢„æµ‹æ˜¯æ•°æ®ç§‘å­¦çš„æ ¸å¿ƒä»»åŠ¡ï¼Œåœ¨ç”µåŠ›è°ƒåº¦ã€é‡‘èé£é™©è¯„ä¼°ç­‰é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ã€‚ä¼ ç»Ÿç¡®å®šæ€§é¢„æµ‹æ–¹æ³•æ— æ³•é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œè€Œç°æœ‰æ¦‚ç‡é¢„æµ‹æ–¹æ³•ï¼ˆå¦‚æ‰©æ•£æ¨¡å‹ï¼‰çš„ç‚¹é¢„æµ‹è´¨é‡æ˜¾è‘—ä½äºç¡®å®šæ€§æ–¹æ³•ã€‚é’ˆå¯¹è¯¥é—®é¢˜ï¼Œæœ¬ç ”ç©¶æå‡º iDiffFormerï¼ˆiTransformer-Diffusion Forecasterï¼‰ï¼Œèåˆå˜é‡çº§æ³¨æ„åŠ›æœºåˆ¶ä¸æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š(1) ç›´æ¥é¢„æµ‹æ‰©æ•£èŒƒå¼ï¼Œä½¿ç›®æ ‡åˆ†å¸ƒæ›´è§„åˆ™ï¼Œè®­ç»ƒæ›´ç¨³å®šï¼›(2) v-prediction å‚æ•°åŒ–ç­–ç•¥ï¼Œåœ¨å„æ—¶é—´æ­¥ä¿æŒå‡è¡¡ä¿¡å™ªæ¯”ï¼›(3) FiLM + VariateCrossAttention åŒé‡æ¡ä»¶æ³¨å…¥æœºåˆ¶ï¼›(4) Median-of-Means èšåˆæ–¹æ³•ï¼Œç‚¹é¢„æµ‹ç²¾åº¦æ”¹å–„ 8.6%ã€‚æœ¬ç ”ç©¶æ—¨åœ¨ä¸ºæ—¶é—´åºåˆ—æ¦‚ç‡é¢„æµ‹æä¾›é«˜è´¨é‡çš„ç‚¹é¢„æµ‹ä¸å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚'''

    gen.add_abstract("æ‘˜  è¦", abstract_content,
                     "æ—¶é—´åºåˆ—é¢„æµ‹ï¼›æ‰©æ•£æ¨¡å‹ï¼›iTransformerï¼›æ¦‚ç‡é¢„æµ‹ï¼›ä¸ç¡®å®šæ€§é‡åŒ–")

    # ========== ç¬¬ä¸€ç«  ==========
    gen.add_heading1("ä¸€ã€ç›®æ ‡åŠæ„ä¹‰ï¼ˆå«å›½å†…å¤–ç ”ç©¶ç°çŠ¶åˆ†æï¼‰")

    gen.add_heading2("1.1 ç ”ç©¶èƒŒæ™¯")
    gen.add_body_text('''æ—¶é—´åºåˆ—é¢„æµ‹æ˜¯æ•°æ®ç§‘å­¦é¢†åŸŸçš„æ ¸å¿ƒä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºç”µåŠ›è´Ÿè·é¢„æµ‹ã€é‡‘èé£é™©è¯„ä¼°ã€æ°”è±¡é¢„æŠ¥ã€äº¤é€šæµé‡ä¼°è®¡ç­‰é¢†åŸŸã€‚ä¼ ç»Ÿçš„æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•ä»¥ç‚¹é¢„æµ‹ä¸ºä¸»ï¼Œå¦‚ ARIMAã€Prophet ç­‰ç»Ÿè®¡æ–¹æ³•ï¼Œä»¥åŠæ·±åº¦å­¦ä¹ æ–¹æ³•å¦‚ LSTMã€Transformer åŠå…¶å˜ä½“ã€‚ç„¶è€Œï¼Œè¿™äº›ç¡®å®šæ€§é¢„æµ‹æ–¹æ³•ä»…è¾“å‡ºå•ä¸€é¢„æµ‹å€¼ï¼Œæ— æ³•é‡åŒ–é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚åœ¨å®é™…å†³ç­–åœºæ™¯ä¸­ï¼Œå†³ç­–è€…ä¸ä»…éœ€è¦çŸ¥é“"é¢„æµ‹å€¼æ˜¯å¤šå°‘"ï¼Œæ›´éœ€è¦çŸ¥é“"è¿™ä¸ªé¢„æµ‹æœ‰å¤šå¯é "ã€‚ä¾‹å¦‚ï¼Œç”µç½‘è°ƒåº¦éœ€è¦è€ƒè™‘è´Ÿè·é¢„æµ‹çš„ç½®ä¿¡åŒºé—´æ¥å®‰æ’å‘ç”µè®¡åˆ’ï¼›é‡‘èæŠ•èµ„éœ€è¦è¯„ä¼°æ”¶ç›Šé¢„æµ‹çš„é£é™©èŒƒå›´ã€‚å› æ­¤ï¼Œèƒ½å¤Ÿæä¾›æ¦‚ç‡åˆ†å¸ƒé¢„æµ‹çš„æ–¹æ³•å…·æœ‰é‡è¦çš„ç†è®ºå’Œå®è·µä»·å€¼ã€‚''')

    gen.add_heading2("1.2 ç ”ç©¶é—®é¢˜")
    gen.add_body_text('''æœ¬ç ”ç©¶è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šå¦‚ä½•åœ¨ä¿æŒé«˜ç²¾åº¦ç‚¹é¢„æµ‹çš„åŒæ—¶ï¼Œæä¾›å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Ÿç°æœ‰æ–¹æ³•é¢ä¸´ä¸¤å¤§å›°å¢ƒï¼šï¼ˆ1ï¼‰æ¦‚ç‡æ¨¡å‹ç‚¹é¢„æµ‹è´¨é‡å·®â€”â€”ç°æœ‰çš„æ¦‚ç‡é¢„æµ‹æ–¹æ³•ï¼ˆå¦‚ TimeGradã€CSDI ç­‰æ‰©æ•£æ¨¡å‹ï¼‰è™½ç„¶èƒ½å¤Ÿæä¾›ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œä½†ç‚¹é¢„æµ‹ç²¾åº¦æ˜¾è‘—ä½äºç¡®å®šæ€§æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨ ETTh1 æ•°æ®é›†ä¸Šï¼ŒTimeGrad çš„ MSE çº¦ä¸º 0.94ï¼Œè€Œç¡®å®šæ€§æ–¹æ³• iTransformer ä»…ä¸º 0.39ï¼Œæ€§èƒ½å·®è·è¾¾ 140%ï¼›ï¼ˆ2ï¼‰è®­ç»ƒä¸ç¨³å®šâ€”â€”æ‰©æ•£æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢†åŸŸçš„è®­ç»ƒå­˜åœ¨ä¸ç¨³å®šé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šé‡‡ç”¨æ®‹å·®é¢„æµ‹ç­–ç•¥ï¼Œç”±äºæ®‹å·®åˆ†å¸ƒä¸è§„åˆ™ï¼Œéœ€è¦å¤æ‚çš„å½’ä¸€åŒ–ç­–ç•¥æ‰èƒ½ä¿è¯æ”¶æ•›ã€‚''')

    gen.add_heading2("1.3 å›½å†…å¤–ç ”ç©¶ç°çŠ¶")

    gen.add_heading3("1.3.1 ç¡®å®šæ€§é¢„æµ‹æ–¹æ³•çš„æ¼”è¿›")
    gen.add_body_text('''æ—¶é—´åºåˆ—é¢„æµ‹ç»å†äº†ä»ç»Ÿè®¡æ¨¡å‹åˆ°æ·±åº¦å­¦ä¹ çš„å‘å±•å†ç¨‹ã€‚æ—©æœŸçš„ ARIMAã€æŒ‡æ•°å¹³æ»‘ç­‰ç»Ÿè®¡æ–¹æ³•åœ¨å•å˜é‡åœºæ™¯è¡¨ç°è‰¯å¥½ï¼Œä½†éš¾ä»¥æ•æ‰å¤æ‚çš„éçº¿æ€§å…³ç³»ã€‚æ·±åº¦å­¦ä¹ æ–¹æ³•çš„å…´èµ·å¸¦æ¥äº† RNNã€LSTMã€GRU ç­‰åºåˆ—æ¨¡å‹ã€‚2017 å¹´ Transformer æ¶æ„çš„æå‡ºä¸ºæ—¶é—´åºåˆ—é¢„æµ‹å¸¦æ¥æ–°çš„èŒƒå¼ï¼ŒInformer (AAAI 2021)ã€Autoformer (NeurIPS 2021)ã€FEDformer (ICML 2022) ç­‰å·¥ä½œåœ¨é•¿åºåˆ—é¢„æµ‹ä¸Šå–å¾—çªç ´ã€‚è¿‘æœŸï¼ŒiTransformer (ICLR 2024) æå‡º"å€’ç½®"æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨å˜é‡ç»´åº¦è€Œéæ—¶é—´ç»´åº¦åº”ç”¨è‡ªæ³¨æ„åŠ›ï¼Œæ˜¾è‘—æå‡äº†å¤šå˜é‡é¢„æµ‹æ€§èƒ½ã€‚''')

    gen.add_heading3("1.3.2 æ‰©æ•£æ¨¡å‹çš„å‘å±•")
    gen.add_body_text('''æ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) ç”± Ho ç­‰äººäº 2020 å¹´æå‡ºï¼Œé€šè¿‡é€æ­¥æ·»åŠ å™ªå£°å†é€æ­¥å»å™ªçš„æ–¹å¼å®ç°ç”Ÿæˆå»ºæ¨¡ï¼Œåœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†ä¼˜å¼‚æˆæœã€‚DDIM (2021) æå‡ºç¡®å®šæ€§é‡‡æ ·æ–¹æ¡ˆï¼Œå°†é‡‡æ ·é€Ÿåº¦æå‡ 10-50 å€ã€‚Salimans ç­‰ (2022) æå‡º v-prediction å‚æ•°åŒ–ï¼Œåœ¨å„æ—¶é—´æ­¥ä¿æŒå‡è¡¡çš„ä¿¡å™ªæ¯”ï¼Œæ”¹å–„äº†è®­ç»ƒç¨³å®šæ€§ã€‚''')

    gen.add_heading3("1.3.3 æ‰©æ•£æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢†åŸŸçš„åº”ç”¨")
    gen.add_body_text('''TimeGrad (ICML 2021) é¦–æ¬¡å°†æ‰©æ•£æ¨¡å‹å¼•å…¥æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œä½¿ç”¨è‡ªå›å½’æ–¹å¼é€æ­¥ç”Ÿæˆæœªæ¥åºåˆ—ã€‚CSDI (NeurIPS 2021) æå‡ºæ¡ä»¶æ‰©æ•£æ¨¡å‹ç”¨äºæ—¶é—´åºåˆ—æ’è¡¥ã€‚D3VAE (NeurIPS 2022) ç»“åˆå˜åˆ†è‡ªç¼–ç å™¨ä¸æ‰©æ•£æ¨¡å‹ã€‚SimDiff (NeurIPS 2023) æå‡º Median-of-Means èšåˆæ–¹æ³•æ”¹å–„ç‚¹é¢„æµ‹è´¨é‡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•æ™®éå­˜åœ¨ç‚¹é¢„æµ‹è´¨é‡ä¸è¶³ã€è®­ç»ƒä¸ç¨³å®šã€æ¡ä»¶æœºåˆ¶ç®€å•ç­‰é—®é¢˜ã€‚''')

    gen.add_heading2("1.4 ç ”ç©¶æ„ä¹‰")
    gen.add_body_text('''æœ¬ç ”ç©¶æå‡ºå°†å˜é‡çº§æ³¨æ„åŠ›æœºåˆ¶ä¸æ¡ä»¶æ‰©æ•£æ¨¡å‹æ·±åº¦èåˆçš„æ–°èŒƒå¼ iDiffFormerï¼ˆiTransformer-Diffusion Forecasterï¼‰ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼Œæœ¬ç ”ç©¶æå‡ºä»¥ä¸‹æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š''')

    gen.add_body_text_bold("åˆ›æ–°ç‚¹ 1ï¼šç›´æ¥é¢„æµ‹æ‰©æ•£èŒƒå¼â€”â€”",
        "ä¸åŒäºç°æœ‰æ–¹æ³•çš„æ®‹å·®é¢„æµ‹ç­–ç•¥ï¼Œæœ¬ç ”ç©¶æå‡ºç›´æ¥é¢„æµ‹ç›®æ ‡åºåˆ—ï¼Œç†è®ºåˆ†æè¡¨æ˜ç›´æ¥é¢„æµ‹çš„ç›®æ ‡åˆ†å¸ƒæ›´è§„åˆ™ï¼Œæ— éœ€é¢å¤–çš„æ®‹å·®å½’ä¸€åŒ–æ¨¡å—ï¼Œè®­ç»ƒæ›´ç¨³å®šã€æ”¶æ•›æ›´å¿«ã€‚")

    gen.add_body_text_bold("åˆ›æ–°ç‚¹ 2ï¼šv-prediction å‚æ•°åŒ–â€”â€”",
        "æœ¬ç ”ç©¶ç³»ç»Ÿæ€§åœ°å¯¹æ¯”äº† xâ‚€-predictionã€Îµ-prediction å’Œ v-prediction ä¸‰ç§å‚æ•°åŒ–ç­–ç•¥ï¼Œæ­ç¤ºäº† v-prediction åœ¨å„æ—¶é—´æ­¥ä¿æŒå‡è¡¡ä¿¡å™ªæ¯”çš„ä¼˜åŠ¿ã€‚")

    gen.add_body_text_bold("åˆ›æ–°ç‚¹ 3ï¼šåŒé‡æ¡ä»¶æ³¨å…¥æœºåˆ¶â€”â€”",
        "è®¾è®¡ FiLMï¼ˆå…¨å±€è°ƒåˆ¶ï¼‰+ VariateCrossAttentionï¼ˆå˜é‡äº¤å‰æ³¨æ„åŠ›ï¼‰ç›¸ç»“åˆçš„æ¡ä»¶æ³¨å…¥æœºåˆ¶ï¼Œå……åˆ†åˆ©ç”¨å†å²åºåˆ—çš„å¤šå˜é‡ä¿¡æ¯ã€‚")

    gen.add_body_text_bold("åˆ›æ–°ç‚¹ 4ï¼šMedian-of-Means èšåˆâ€”â€”",
        "å€Ÿé‰´ SimDiff æå‡ºçš„ MoM æ–¹æ³•ï¼Œå°†å¤šä¸ªé‡‡æ ·åˆ†ç»„åå–ç»„å‡å€¼çš„ä¸­ä½æ•°ï¼Œå®éªŒè¡¨æ˜è¯¥æ–¹æ³•ä½¿ç‚¹é¢„æµ‹ MSE æ”¹å–„ 8.6%ã€‚")

    # ========== ç¬¬äºŒç«  ==========
    gen.add_heading1("äºŒã€ç ”ç©¶è®¾è®¡çš„åŸºæœ¬å†…å®¹ã€ç›®æ ‡ã€æ‹Ÿé‡‡ç”¨çš„æŠ€æœ¯æ–¹æ¡ˆåŠæªæ–½")

    gen.add_heading2("2.1 ç ”ç©¶ç›®æ ‡")
    gen.add_body_text('''æœ¬ç ”ç©¶æ—¨åœ¨è®¾è®¡ä¸€ç§èåˆå˜é‡çº§æ³¨æ„åŠ›æœºåˆ¶ä¸æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„æ—¶é—´åºåˆ—æ¦‚ç‡é¢„æµ‹æ–¹æ³• iDiffFormerï¼Œå®ç°ä»¥ä¸‹ç›®æ ‡ï¼šï¼ˆ1ï¼‰é«˜è´¨é‡çš„ç‚¹é¢„æµ‹ï¼Œç¼©å°ä¸ç¡®å®šæ€§æ–¹æ³•çš„å·®è·ï¼›ï¼ˆ2ï¼‰å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæä¾›æ ¡å‡†è‰¯å¥½çš„é¢„æµ‹åŒºé—´ï¼›ï¼ˆ3ï¼‰é«˜æ•ˆçš„è®­ç»ƒä¸æ¨ç†ï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²åœºæ™¯ã€‚''')

    gen.add_heading2("2.2 ç†è®ºåŸºç¡€")
    gen.add_body_text("æ‰©æ•£æ¨¡å‹åŒ…å«å‰å‘åŠ å™ªå’Œé€†å‘å»å™ªä¸¤ä¸ªè¿‡ç¨‹ã€‚å‰å‘è¿‡ç¨‹å®šä¹‰ä¸ºï¼š")

    # å‰å‘æ‰©æ•£å…¬å¼ï¼ˆç‹¬ç«‹ä¸€è¡Œï¼‰
    gen.add_formula_paragraph(build_forward_diffusion_formula())

    gen.add_body_with_formula([
        "å…¶ä¸­ ",
        ('formula', _omml_sub('Î²', 't')),
        " ä¸ºå™ªå£°è°ƒåº¦å‚æ•°ã€‚é€†å‘å»å™ªè¿‡ç¨‹ä¸ºï¼š"
    ])

    # é€†å‘å»å™ªå…¬å¼ï¼ˆç‹¬ç«‹ä¸€è¡Œï¼‰
    gen.add_formula_paragraph(build_reverse_diffusion_formula())

    gen.add_body_with_formula([
        "é€šè¿‡å­¦ä¹ å™ªå£°é¢„æµ‹ç½‘ç»œ ",
        ('formula', build_noise_pred_formula()),
        "ï¼Œæ¨¡å‹å¯ä»¥ä»çº¯å™ªå£°é€æ­¥æ¢å¤å‡ºåŸå§‹æ•°æ®ã€‚æ¡ä»¶æ‰©æ•£æ¨¡å‹å¼•å…¥æ¡ä»¶ç‰¹å¾ cï¼Œä½¿ç”Ÿæˆè¿‡ç¨‹ä¾èµ–äºè¾“å…¥æ¡ä»¶ï¼Œæ¡ä»¶æ³¨å…¥æœºåˆ¶é€šè¿‡ FiLM è°ƒåˆ¶æˆ–äº¤å‰æ³¨æ„åŠ›å°†æ¡ä»¶ä¿¡æ¯èå…¥å»å™ªç½‘ç»œã€‚"
    ])

    gen.add_heading2("2.3 ç ”ç©¶å†…å®¹")

    gen.add_heading3("2.3.1 iTransformer æ¡ä»¶ç‰¹å¾æå–å™¨")
    gen.add_body_with_formula([
        "é‡‡ç”¨ iTransformer ä½œä¸ºæ¡ä»¶ç‰¹å¾æå–å™¨ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°æ˜¯å°†è‡ªæ³¨æ„åŠ›ä»æ—¶é—´ç»´åº¦è½¬ç§»åˆ°å˜é‡ç»´åº¦ã€‚å¯¹äºè¾“å…¥åºåˆ— ",
        ('formula', build_dimension_formula('X', 'BÃ—TÃ—N')),
        "ï¼Œé€šè¿‡çº¿æ€§æŠ•å½±å°†æ—¶é—´ç»´åº¦å‹ç¼©åˆ°éšç©ºé—´ï¼Œç„¶ååœ¨å˜é‡ç»´åº¦åº”ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼Œæ•æ‰å˜é‡é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚ç¼–ç å™¨è¾“å‡º ",
        ('formula', build_dimension_formula('z', 'BÃ—NÃ—d')),
        " åŒ…å«æ¯ä¸ªå˜é‡çš„å…¨å±€è¡¨ç¤ºï¼Œé€‚åˆä½œä¸ºæ‰©æ•£æ¨¡å‹çš„æ¡ä»¶è¾“å…¥ã€‚"
    ])

    gen.add_heading3("2.3.2 ç›´æ¥é¢„æµ‹æ‰©æ•£æ¨¡å‹è®¾è®¡")
    gen.add_body_with_formula([
        "åŒºåˆ«äºç°æœ‰æ–¹æ³•çš„æ®‹å·®é¢„æµ‹ç­–ç•¥ï¼ˆé¢„æµ‹ ",
        ('formula', _omml_sub('y', 'true')),
        " - ",
        ('formula', _omml_sub('y', 'det')),
        "ï¼‰ï¼Œæœ¬ç ”ç©¶é‡‡ç”¨ç›´æ¥é¢„æµ‹æ–¹å¼ï¼ˆç›´æ¥é¢„æµ‹ ",
        ('formula', _omml_sub('y', 'true')),
        "ï¼‰ã€‚åŒæ—¶ï¼Œç³»ç»Ÿæ€§åœ°å®ç°ä¸‰ç§å‚æ•°åŒ–ç­–ç•¥ï¼š"
    ])
    gen.add_body_with_formula([
        "ï¼ˆ1ï¼‰",
        ('formula', _omml_sub('x', '0')),
        "-predictionï¼šç›´æ¥é¢„æµ‹å¹²å‡€æ•°æ®ï¼›ï¼ˆ2ï¼‰Îµ-predictionï¼šé¢„æµ‹å™ªå£°ï¼ŒDDPM æ ‡å‡†æ–¹æ³•ï¼›ï¼ˆ3ï¼‰v-predictionï¼šé¢„æµ‹ vï¼Œæœ¬ç ”ç©¶æ¨èã€‚v-prediction å®šä¹‰ä¸ºï¼š"
    ])

    # v-prediction å…¬å¼ï¼ˆç‹¬ç«‹ä¸€è¡Œï¼‰
    gen.add_formula_paragraph(build_v_prediction_formula())

    gen.add_body_text("v-prediction åœ¨æ‰€æœ‰æ—¶é—´æ­¥ä¿æŒç›¸å¯¹ç¨³å®šçš„ä¿¡å™ªæ¯”ï¼Œè®­ç»ƒç¨³å®šæ€§æœ€é«˜ã€‚")

    gen.add_heading3("2.3.3 æ¡ä»¶æ³¨å…¥æœºåˆ¶è®¾è®¡")
    gen.add_body_with_formula([
        "è®¾è®¡ FiLM + VariateCrossAttention çš„åŒé‡æ¡ä»¶æ³¨å…¥æœºåˆ¶ï¼šFiLM å±‚é€šè¿‡å¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•° Î³ å’Œå¹³ç§»å‚æ•° Î² å¯¹å»å™ªç½‘ç»œçš„ç‰¹å¾è¿›è¡Œè°ƒåˆ¶ï¼Œå…¬å¼ä¸º ",
        ('formula', build_film_formula()),
        "ï¼Œå®ç°å…¨å±€æ¡ä»¶æ³¨å…¥ï¼›å˜é‡äº¤å‰æ³¨æ„åŠ›ä½¿å»å™ªç½‘ç»œçš„è¾“å‡ºä½œä¸º Queryï¼Œç¼–ç å™¨ç‰¹å¾ä½œä¸º Key/Valueï¼Œå®ç°ç²¾ç»†åŒ–çš„æ¡ä»¶èåˆã€‚åŒé‡æœºåˆ¶ç»“åˆäº†å…¨å±€è°ƒæ§å’Œå±€éƒ¨ä¾èµ–å»ºæ¨¡çš„ä¼˜åŠ¿ã€‚"
    ])

    gen.add_heading2("2.4 å®éªŒè®¾è®¡")
    gen.add_body_text('''æœ¬ç ”ç©¶ä½¿ç”¨ ETTï¼ˆElectricity Transformer Temperatureï¼‰ç³»åˆ—æ•°æ®é›†è¿›è¡Œå®éªŒéªŒè¯ï¼ŒåŒ…æ‹¬ ETTh1/h2ï¼ˆå°æ—¶çº§ï¼‰å’Œ ETTm1/m2ï¼ˆ15åˆ†é’Ÿçº§ï¼‰ï¼Œå…± 7 ä¸ªå˜é‡ï¼ŒæŒ‰ 6:2:2 æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚é¢„æµ‹ä»»åŠ¡é…ç½®ä¸ºå†å²çª—å£ 96 æ­¥é¢„æµ‹æœªæ¥ 96/192/336/720 æ­¥ã€‚''')

    gen.add_body_text('''åŸºçº¿æ–¹æ³•åŒ…æ‹¬ç¡®å®šæ€§æ–¹æ³•ï¼ˆiTransformerã€PatchTSTã€TimesNetã€DLinearï¼‰å’Œæ¦‚ç‡æ–¹æ³•ï¼ˆTimeGradã€CSDIã€D3VAEï¼‰ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ç‚¹é¢„æµ‹æŒ‡æ ‡ï¼ˆMSEã€MAEï¼‰ã€æ¦‚ç‡é¢„æµ‹æŒ‡æ ‡ï¼ˆCRPSã€Calibrationã€Sharpnessï¼‰å’Œæ•ˆç‡æŒ‡æ ‡ï¼ˆè®­ç»ƒæ—¶é—´ã€æ¨ç†é€Ÿåº¦ï¼‰ã€‚æ‰€æœ‰å®éªŒé‡å¤ 3 æ¬¡ï¼Œä½¿ç”¨é…å¯¹ t æ£€éªŒåˆ¤æ–­æ”¹è¿›æ˜¾è‘—æ€§ã€‚''')

    gen.add_body_text('''æ¶ˆèå®éªŒè®¾è®¡åŒ…æ‹¬ï¼šå‚æ•°åŒ–ç­–ç•¥å¯¹æ¯”ï¼ˆxâ‚€/Îµ/vï¼‰ã€è®­ç»ƒç­–ç•¥å¯¹æ¯”ï¼ˆç«¯åˆ°ç«¯ vs ä¸¤é˜¶æ®µï¼‰ã€æ¡ä»¶æœºåˆ¶æ¶ˆèï¼ˆFiLM/CrossAttentionï¼‰ã€èšåˆæ–¹æ³•å¯¹æ¯”ï¼ˆå‡å€¼ vs MoMï¼‰ã€‚''')

    # ========== ç¬¬ä¸‰ç«  ==========
    gen.add_heading1("ä¸‰ã€è¿›åº¦å®‰æ’")

    gen.add_body_text("æœ¬ç ”ç©¶è®¡åˆ’åœ¨ 3 ä¸ªæœˆï¼ˆ12 å‘¨ï¼‰å†…å®Œæˆï¼Œå…·ä½“è¿›åº¦å®‰æ’å¦‚ä¸‹ï¼š", first_indent=False)

    schedule_data = [
        ("æ–‡çŒ®è°ƒç ”", "ç¬¬1-2å‘¨", "é˜…è¯»æ‰©æ•£æ¨¡å‹å’Œæ—¶åºé¢„æµ‹ç›¸å…³æ–‡çŒ®ï¼Œæ•´ç†ç ”ç©¶ç°çŠ¶"),
        ("ç†è®ºåˆ†æ", "ç¬¬3å‘¨", "åˆ†æç›´æ¥é¢„æµ‹ vs æ®‹å·®é¢„æµ‹ï¼Œæ¨å¯¼å‚æ•°åŒ–æ•°å­¦å…³ç³»"),
        ("æ¨¡å‹å®ç°", "ç¬¬4-6å‘¨", "å®ç° iDiffFormer æ ¸å¿ƒæ¨¡å—ï¼Œä»£ç è°ƒè¯•ä¸å•å…ƒæµ‹è¯•"),
        ("åŸºçº¿å¤ç°", "ç¬¬7å‘¨", "å¤ç° iTransformer åŸºçº¿ï¼Œç»Ÿä¸€è¯„ä¼°æ¡†æ¶"),
        ("ä¸»å®éªŒ", "ç¬¬8-9å‘¨", "ETTh1/h2 æ•°æ®é›†å®éªŒï¼ŒæŒ‡æ ‡è¯„ä¼°"),
        ("æ¶ˆèå®éªŒ", "ç¬¬10å‘¨", "å‚æ•°åŒ–ç­–ç•¥ã€è®­ç»ƒç­–ç•¥ã€æ¡ä»¶æœºåˆ¶æ¶ˆè"),
        ("è®ºæ–‡æ’°å†™", "ç¬¬11å‘¨", "æ’°å†™æ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•è®¾è®¡ã€å®éªŒç« èŠ‚"),
        ("ä¿®æ”¹å®Œå–„", "ç¬¬12å‘¨", "è®ºæ–‡ä¿®æ”¹æ¶¦è‰²ï¼Œå‡†å¤‡ç­”è¾©ææ–™"),
    ]
    gen.add_schedule_table(schedule_data)

    # ========== ç¬¬å››ç«  ==========
    gen.add_heading1("å››ã€å‚è€ƒæ–‡çŒ®")

    references = [
        "[1] HO J, JAIN A, ABBEEL P. Denoising diffusion probabilistic models[C]//Advances in Neural Information Processing Systems 33. Red Hook: Curran Associates, 2020: 6840-6851.",
        "[2] SONG J, MENG C, ERMON S. Denoising diffusion implicit models[C]//International Conference on Learning Representations. [S.l.]: OpenReview.net, 2021.",
        "[3] SALIMANS T, HO J. Progressive distillation for fast sampling of diffusion models[C]//International Conference on Learning Representations. [S.l.]: OpenReview.net, 2022.",
        "[4] LIU Y, HU T, ZHANG H, et al. iTransformer: Inverted transformers are effective for time series forecasting[C]//International Conference on Learning Representations. [S.l.]: OpenReview.net, 2024.",
        "[5] RASUL K, SEWARD C, SCHUSTER I, et al. Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting[C]//Proceedings of the 38th ICML. [S.l.]: PMLR, 2021: 8857-8868.",
        "[6] TASHIRO Y, SONG J, SONG Y, et al. CSDI: Conditional score-based diffusion models for probabilistic time series imputation[C]//NeurIPS 34. Red Hook: Curran Associates, 2021: 24804-24816.",
        "[7] LI Y, LU X, WANG Y, et al. Generative time series forecasting with diffusion, denoise, and disentanglement[C]//NeurIPS 35. Red Hook: Curran Associates, 2022: 23009-23022.",
        "[8] ZHOU H, ZHANG S, PENG J, et al. Informer: Beyond efficient transformer for long sequence time-series forecasting[C]//AAAI 2021. Menlo Park: AAAI Press, 2021: 11106-11115.",
        "[9] WU H, XU J, WANG J, et al. Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting[C]//NeurIPS 34. Red Hook: Curran Associates, 2021: 22419-22430.",
        "[10] ZHOU T, MA Z, WEN Q, et al. FEDformer: Frequency enhanced decomposed transformer for long-term series forecasting[C]//ICML 2022. [S.l.]: PMLR, 2022: 27268-27286.",
        "[11] NIE Y, NGUYEN N H, SINTHONG P, et al. A time series is worth 64 words: Long-term forecasting with transformers[C]//ICLR. [S.l.]: OpenReview.net, 2023.",
        "[12] WU H, HU T, LIU Y, et al. TimesNet: Temporal 2D-variation modeling for general time series analysis[C]//ICLR. [S.l.]: OpenReview.net, 2023.",
        "[13] DHARIWAL P, NICHOL A. Diffusion models beat GANs on image synthesis[C]//NeurIPS 34. Red Hook: Curran Associates, 2021: 8780-8794.",
        "[14] ROMBACH R, BLATTMANN A, LORENZ D, et al. High-resolution image synthesis with latent diffusion models[C]//CVPR 2022. Piscataway: IEEE, 2022: 10684-10695.",
        "[15] KOLLOVIEH M, ANSARI A F, BOHLKE-SCHNEIDER M, et al. Predict, refine, synthesize: Self-guiding diffusion models for probabilistic time series forecasting[C]//NeurIPS 36. Red Hook: Curran Associates, 2023.",
        "[16] GNEITING T, RAFTERY A E. Strictly proper scoring rules, prediction, and estimation[J]. Journal of the American Statistical Association, 2007, 102(477): 359-378.",
        "[17] VASWANI A, SHAZEER N, PARMAR N, et al. Attention is all you need[C]//NeurIPS 30. Red Hook: Curran Associates, 2017: 5998-6008.",
    ]

    for ref in references:
        gen.add_reference(ref)

    # ========== ä¿å­˜ ==========
    output_path = os.path.join(os.path.dirname(__file__), "å¼€é¢˜æŠ¥å‘Š_v2.docx")
    gen.save(output_path)
    return output_path


if __name__ == "__main__":
    output = generate_proposal()
    print(f"\nå¼€é¢˜æŠ¥å‘Šå·²ç”Ÿæˆï¼š{output}")
    print("è¯·åœ¨ Word ä¸­æ‰“å¼€æ£€æŸ¥æ ¼å¼ï¼Œå¹¶å¡«å†™å°é¢ä¿¡æ¯ï¼ˆå­¦ç”Ÿå§“åã€ä¸“ä¸šç­çº§ã€æŒ‡å¯¼æ•™å¸ˆã€å®Œæˆæ—¶é—´ï¼‰")
